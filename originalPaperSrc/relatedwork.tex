\section{Related Work}
\label{Sec-RelatedWork}

In \cite{pqhunt}, a heap-like structure has a global lock, used to change the counters that indicate available nodes, and each node also has a private lock. When we insert an element, we change the position counters (after acquiring the global lock), and traverse the tree upwards, locking the parent and the child nodes at each step.
%The element inserted might be moved up by a concurrent removal operation, an in this case, the thread essentially continues upwards, trying to re encounter its node. (this is controlled through a status field and an ownership tag present in each node). When we remove an element, we again change the position counters (after acquiring the global lock), and we traverse the tree downwards, basically doing exactly as the sequential algorithm, but using hand-over-hand locking to synchronize element swaps.
In the skiplist-based implementation of~\cite{Lotan2000}, \texttt{add()} and \texttt{removeMin()} operations of the priority queue are implemented using a skiplist, as in this work. There, each node has a ``deleted'' flag, and processors contend to mark such ``deleted'' flags concurrently, in the beginning of the list. When a thread logically deletes a node, it tries to remove it from the skiplist using the standard removal algorithm.% Additionally, threads ignore nodes whose timestamp (acquired when inserted in the skiplist) is smaller than the moment the traversal at the bottom level list started. This timestamp mechanism is necessary for linearizability. The insert and removal algorithms are straightforward implementations of a fine-grain lock-based skiplist.

Another skiplist implementation is presented in \cite{pqsundelltsigas}. It essentially implements the same idea as \cite{Lotan2000}, however is lock-free and addresses issues related to real-time systems. % Every time logically deleted nodes are visited, the visiting threads help the removing thread to finish its operation. This implementation has an interesting optimization of having a pointer to the previous element (set when the node was logically deleted), so helping threads avoid having to traverse the bottom level list to physically remove the node. They also have another mechanism to backoff helping threads after some failed attempts of doing so.
In \cite{pqsurvey}, the authors present a comparison between \cite{pqhunt} and \cite{pqsundelltsigas} (along a coarse-grained locking version and an STM-based version using DTSM). The lock-free skiplist-based priority queue basically shows better performance and scalability than the heap-based implementation (with varying cores/threads ratio). The STM-based implementation performs slowly. They show good results for the coarse-grained locking version under higher contention tests.

% Flat-combining, Rendezvouz, Elimination for {Stack,Queue}
Hendler et al.~\cite{Hendler2010} introduced Flat Combining, which was evaluated for different data structures. Elimination was initially presented in the context of stacks~\cite{Hendler2010a}, but there are versions suitable for queues as well~\cite{Moir2005}.
%Concurrent threads compete for a coarse grain lock on the shared data structure; the lock winner executes all pending operations. Flat combining was designed and evaluated for different data structures, including a priority queue implemented as a skiplist. Batching concurrent \texttt{removeMin()} operations in a skiplist is beneficial because several items can be deleted from the data structure with only one operation. Combining can be useful for skiplist \texttt{add()} operations as well: concurrent requests can be sorted and inserted sequentially with only one skiplist traversal.
%However, the skiplist could be faster and more scalable if \texttt{add()} operations that do not conflict with one another and with the \texttt{removeMin()} operations were inserted in parallel. Therefore, our first design decision was to combine sequential \texttt{removeMin()} operations and parallel \texttt{add()} operations in the same data structure, a dual skiplist.   
Finally, \cite{Afek2011} describes a system where producers and consumers efficiently match service requests and executions in a manner similar to this work.

%TODO
Delegation of work using a server thread has been studied before in other work~\cite{Metreveli2012}, \cite{DBLP:conf/opodis/CalciuDHHKMM13}, \cite{HotPar13Stack}.
