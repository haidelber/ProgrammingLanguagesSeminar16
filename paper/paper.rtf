{\rtf1\ansi\uc1\deff0\deflang1024
{\fonttbl{\f0\fnil\fcharset0 Times New Roman;}
{\f1\fnil\fcharset0 Arial;}
{\f2\fnil\fcharset0 Arial;}
{\f3\fnil\fcharset0 Courier New;}
{\f4\fnil\fcharset0 Zapf Chancery;}
{\f5\fnil\fcharset0 STIXGeneral;}
{\f6\fnil\fcharset0 MS Gothic;}
}
{\colortbl;
\red0\green0\blue0;
\red0\green0\blue255;
\red0\green255\blue255;
\red0\green255\blue0;
\red255\green0\blue255;
\red255\green0\blue0;
\red255\green255\blue0;
\red255\green255\blue255;
}
{\stylesheet
{\s0\qj\widctlpar\f0\fs20 \snext0 Normal;}
{\cs10 \additive\ssemihidden Default Paragraph Font;}
{\s1\qc\sb240\sa120\keepn\f0\b\fs40 \sbasedon0\snext0 Part;}
{\s2\ql\sb240\sa120\keepn\f0\b\fs40 \sbasedon0\snext0 heading 1;}
{\s3\ql\sb240\sa120\keepn\f0\b\fs32 \sbasedon0\snext0 heading 2;}
{\s4\ql\sb240\sa120\keepn\f0\b\fs32 \sbasedon0\snext0 heading 3;}
{\s5\ql\sb240\sa120\keepn\f0\b\fs24 \sbasedon0\snext0 heading 4;}
{\s6\ql\sb240\sa120\keepn\f0\b\fs24 \sbasedon0\snext0 heading 5;}
{\s7\ql\sb240\sa120\keepn\f0\b\fs24 \sbasedon0\snext0 heading 6;}
{\s8\qr\sb120\sa120\keep\widctlpar\f0 \sbasedon0\snext8 rightpar;}
{\s9\qc\sb120\sa120\keep\widctlpar\f0 \sbasedon0\snext9 centerpar;}
{\s10\ql\sb120\sa120\keep\widctlpar\f0 \sbasedon0\snext10 leftpar;}
{\s11\ql\sb120\sa120\keep\widctlpar\f0 \sbasedon0\snext0 equation;}
{\s12\ql\sb120\sa120\keep\widctlpar\f0 \sbasedon0\snext0 equationNum;}
{\s13\ql\sb120\sa120\keep\widctlpar\f0 \sbasedon0\snext0 equationAlign;}
{\s14\ql\sb120\sa120\keep\widctlpar\f0 \sbasedon0\snext0 equationAlignNum;}
{\s15\ql\sb120\sa120\keep\widctlpar\f0 \sbasedon0\snext0 equationArray;}
{\s16\ql\sb120\sa120\keep\widctlpar\f0 \sbasedon0\snext0 equationArrayNum;}
{\s17\ql\sb120\sa120\keep\widctlpar\f0\fs20 \sbasedon0\snext0 theorem;}
{\s18\ql\sb120\sa120\keep\widctlpar\f0 \sbasedon0\snext0 bitmapCenter;}
{\s20\qc\sb240\sa240\b\f0\fs36 \sbasedon0\snext21 Title;}
{\s21\qc\sa120\f0\fs20 \sbasedon0\snext0 author;}
{\s22\ql\tqc\tx4536\tqr\tx9072\f0\fs20 \sbasedon0\snext22 footer;}
{\s23\ql\tqc\tx4536\tqr\tx9072\f0\fs20 \sbasedon0\snext23 header;}
{\s30\ql\sb120\sa120\keep\widctlpar\f0 \sbasedon0\snext0 caption;}
{\s31\qc\sb120\sa0\keep\widctlpar\f0\fs20 \sbasedon0\snext0 Figure;}
{\s32\qc\sb120\sa0\keep\widctlpar\f0\fs20 \sbasedon0\snext32 Table;}
{\s33\qc\sb120\sa0\keep\widctlpar\f0\fs20 \sbasedon0\snext33 Tabular;}
{\s34\qc\sb120\sa0\keep\widctlpar\f0\fs20 \sbasedon0\snext34 Tabbing;}
{\s35\qj\li1024\ri1024\fi340\widctlpar\f0\fs20 \sbasedon0\snext35 Quote;}
{\s38\ql\widctlpar\f3\fs20 \snext38 verbatim;}
{\s46\ql\fi-283\li283\lin283\sb0\sa120\widctlpar\tql\tx283\f0\fs20 \sbasedon0\snext46 List;}
{\s47\ql\fi-283\li283\lin283\sb0\sa120\widctlpar\tql\tx283\f0\fs20 \sbasedon0\snext47 List 1;}
{\s50\qc\sb120\sa120\keep\widctlpar\f0 \sbasedon0\snext0 latex picture;}
{\s51\qc\sb120\sa120\keep\widctlpar\f0 \sbasedon0\snext0 subfigure;}
{\s61\ql\sb240\sa120\keepn\f0\b\fs32 \sbasedon0\snext62 bibheading;}
{\s62\ql\fi-567\li567\sb0\sa0\f0\fs20 \sbasedon0\snext62 bibitem;}
{\s64\ql\fi-283\li283\lin283\sb0\sa120\widctlpar\tql\tx283\f0\fs20 \sbasedon0\snext64 endnotes;}
{\s65\ql\fi-113\li397\lin397\f0\fs20 \sbasedon0\snext65 footnote text;}
{\s66\qj\fi-170\li454\lin454\f0\fs20 \sbasedon0\snext66 endnote text;}
{\cs62\super \additive\sbasedon10 footnote reference;}
{\cs63\super \additive\sbasedon10 endnote reference;}
{\s67\ql\sb60\sa60\keepn\f0\fs20 \sbasedon0\snext67 acronym;}
{\s70\qc\sa120\b\f0\fs20 \sbasedon0\snext71 abstract title;}
{\s71\qj\li1024\ri1024\fi340\widctlpar\f0\fs20 \sbasedon0\snext0 abstract;}
{\s80\ql\sb240\sa120\keepn\f0\b\fs20 \sbasedon0\snext0 contents_heading;}
{\s81\ql\li425\tqr\tldot\tx8222\sb240\sa60\keepn\f0\fs20\b \sbasedon0\snext82 toc 1;}
{\s82\ql\li512\tqr\tldot\tx8222\sb60\sa60\keepn\f0\fs20 \sbasedon0\snext83 toc 2;}
{\s83\ql\li1024\tqr\tldot\tx8222\sb60\sa60\keepn\f0\fs20 \sbasedon0\snext84 toc 3;}
{\s84\ql\li1536\tqr\tldot\tx8222\sb60\sa60\keepn\f0\fs20 \sbasedon0\snext85 toc 4;}
{\s85\ql\li2048\tqr\tldot\tx8222\sb60\sa60\keepn\f0\fs20 \sbasedon0\snext86 toc 5;}
{\s86\ql\li2560\tqr\tldot\tx8222\sb60\sa60\keepn\f0\fs20 \sbasedon0\snext86 toc 6;}
}
{\info
{\title Original file was paper.tex}
{\doccomm Created using latex2rtf 2.3.11 r1245 (released Jun 03 2016) on Fri Feb 24 19:15:08 2017
}
}
{\footer\pard\plain\f0\fs20\qc\chpgn\par}
\paperw11960\paperh16900\margl2500\margr2560\margt2520\margb1820\pgnstart0\widowctrl\qj\ftnbj\f0\aftnnar
{{{\page
\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \fi0   
{\pict\picscalex17\picscaley17\picw358\pich357\picwgoal5729\pichgoal5713\pngblip
89504e470d0a1a0a0000000d4948445200000166000001650806000000d8b242b800000006624b474400ff00ff00ffa0bda793000000097048597300000dd700000dd70142289b780000000774494d4507df040f0d263a8f557b09000020004944415478daeddd777813f5e307f077d2a449d33da16c2a20207bc8de1bd91b
51f65096020a88826c110101190202225336884c990ac82e7bcaa6d0bd57e6ef0fbef0633497bb246dd3f4fd7a1e9fe7fbe5ae97e4c6fbee3e53f67877fe0232031e8188881cc11339f701119163613013113198898888c14c44c460262222063311118399888818cc44440c662222623013113198898888c14c44440c6622
22063311113198898818cc4444c4602622623013111183998888c14c44440c662222623013113198898888c14c4494e329b80b8832d7f663a9f86a519ca8755bd776c3cca13ea2d63d7d4d8b5e93a345ad5bb9a42bd64cf4e7c1603013110068752624241b45ad9b9c6a14bd5dbd5efc7613538c3c1039088b32888818cc44
44c4602622623013111183998888c14c44440c662222063311113198898818cc4444c460262222063311118399888818cc44440c662222623013113198898888c14c44c460262222063311113198898818cc4444c4602622623013111183998888c14c44440c662222063311113198898888c14c44c4602622220633111183
99888818cc44440c662222623013113198898888c14c44440c662222063311113198898818cc4444c4602622623013111183998888c14c44440c662222623013113198898888c14c44c460262222063311118399888818cc44440c662222623013111183998888c14c44440c662222063311113198898818cc4444c4602622
62301311118399888818cc44440c662222623013113198898888c14c44c460262222063311118399888818cc4444c4602622623013111183998888c14c44440c662222063311113198898818cc4444c460262222063311118399888818cc44440c662222623013113198898888c14c44c460262222063311118399888818cc
4444c4602622623013111183998888c14c44440c662222063311113198898818cc4444c460262222063311118399888818cc44440c662222623013113198898888c14c44c460262222063311113198898818cc4444c4602622623013111183998888c14c44440c662222063311113198898888c14c44c46026222206331111
8399888818cc44440c662222623013113198898888c14c44440c662222063311113198898818cc4444c4602622623013111183998888c14c44440c662222623013113198898888c14c44c460262222063311118399888818cc44440c662222623013111183998888c14c44440c662222063311113198898818cc4444c46026
2262301311118399888818cc44440c662222623013113198898888c14c44c460262222063311118399888818cc4444c4602622623013111183998888c14c44440c6622220633111131988988720545567ed86fbb93316375824ddbf07697412697c1db5d06b95c86bc7e72140852a0601e17140852e0dd420a14cda7e09125
a20c351e168147e17a51ebee9b178422c1599f2759fa89e93a13e2938c366d233ec9f23a79fd5d50b3ac0a35cba9f0414d35bcdcf9624044cf25a71a91946a12b5aec1983ddfd12913eb59b4015b8fa4e08bf9b1a8d8f319c62d8e43448c81672411e5084eff2899a63561d5ee64d41d1c81357b9379c48988c1ec2812938d
18b3300ea317c465dbeb0911118339036bf72563d08c18e8f4261e7d2262303b8a3d2753317a411c8f3e1131981dc9c683292c73262206b3a399ba321ee16cad41440c66c7919862c2cc35093c0b8888c12cea8bc9006f0ff95bffa95c6576fd9cad47521119c7661a44e4381cb6efb2bfb71ca1ab83cd2e4f49332122d680
7b617adc7f6ac0dfa16938782e1d7a89ad2db43a13361c48c6b0ce9e3c1b88884fccb6d0a8652812ac4083ca6af469e58e15dff8e3f08220542de52a795b074ea7f14c202206736608c9afc0c66901a8575125e9ef426f691197c8e20c22720c4e370c9bab5286455ffaa1f6a070c48a0c5b8311b8764f879ae55499f6bd92
d34cb8784b8bbb617a3c0c37202ed188f8e4e7df4fe92283a7bb0c05025df04e01252abdab4490af4b8edbf749a9261cbf948ecb77b4781461409ad684607f174cecef9d699ff92cda808b777478f8ecf97e4d4c312235fd7971969b4a066f773942f22b50bc8002954aba426de73a0aca58649c11976efffff9feea71512b
65707793a140900285f3baa04c881285833922a453073300f878ca31a8bd0766fc26bec5c59dc77abb07f3c37003761c4bc1de9369b872570bbdc89679321950b2b0126deab8a15b138dd990de7a2405a7ae6a2d6eaf6115359a55535b5c4fab3361fcd27851df71627f6fb8a99e875c628a09b3d62660edbee49717df0b25
0a2a00d82f988d26e0cc352db61f4bc1e1b369781421beb9a3ca5586eaefb9a26b6377b4aca986529171484f5a1e8f9434cb75159f75f544be0017a6c82b6f9edb8fa5e2d0d934fcf7442fe96ff3f8b9a04e0515dad575439d0a6a2872f96e75dadb54fb7a1a49c1fc28426fb7cf3e735d8b059b1271f06c1a4c56f4fc3699
80ebf775b87e5f8739eb13f151730d4676f7829fd7eb254fa7af69457592f1f3928b0a669d01a23bdd8cebe50537950c771eebf1f1c4283c0ccfdcf6e03abd095b0ea762d19644c917fd0be95a138e5e48c7d10be908f273c1973d3cd1b5b13b5cde28d0db7c2805310996dfb67ab670cff5c1ac37003bff4ec1c22d49b871
5f67f576c2630cd87c28059b0fa520afbf0b06b5f3408fe6ee7057e7ce371ca76dc75c20c845527140628aed6367844519d07f7a0cda8d8ec45f67ac0be58c0269e5ae64d41e148edd27521d6a1fdf7da24787b191991ecac742d3d160480446cd8fb53a94df141163c0973fc5a1cd979178f04c0f92ee9f8be96834341cc3
66c7da14ca6f7a166dc0a4e5f1a835e019b61e4961303b9b205ff13f2fc9c660de723805f53f0dc79e9399139ef149460cf82e065356c4db25f06dfe3ec9267c34311ad1f19957699aa635e1cb9fe2d07d7c14ee85654e7886ded2a2d9e79138729e2d73c44a4e33e1f3b9b1e8fa4d14ee3ccebc9b5a649c11c366c7e2a389
d1a2de6018cc398494fc925bb9270c4660dce2380c9f138be4b4cc4fcc9fb72561d4fc5818b3399c472f88cdd427cdb02803da7c198975fb337f3c93c464237a4f89c19f0ef646e2886e3fd2a3e588086c3a98754fb287cfa5a1d9671108bdadcd35fbd9a983392c52fc2bb6879bf4b22c9dde84213fc460d5eeac1d0ce9f7
bf52306d657cb6eedbbf43d3336ddb0fc30de8342e0a57efeab2ecf7e8f4260cfe2116272ea583ccbc5ddcd6a2c3d8c84c7d4a16ba51771e1795a9e71d83398b0e649c84f905bd3da4ed0aa30918f2432cfef8277b9eb27ede9684bfcea439e5716b3f26120f9e66fdc5afd79b3070468ca81619b9cdc92be9e83c2e2a5b8b
1452d24ce835251a272f3b7f383b6d30fffe578aa4b2d81089336b4f5e1e9fedafbe4fa39c6b64bc8464233e9e188d67d1d9f7bb62138d48d332985f75e3be0efda639c60d2b5d6b429fa9d176ad6c6430679187e106fcb23349d2df142f283e98ff3c918a653b9278c5dad9988571b8f140c71de14022e38ce8fe6db4cdb3
dbdb53628a09fdbf8bc9923a9dece274ed98a3e28d18303d5a52176b8d5a86d24595a25fb5bffcc9b6d94f940a19aa9676c53bf91508f491c3c7538e846413a2e30d78f0cc807fafa43bcdebb49b4adcbd7fe3c114ecfcdbb637105f4f396a96552138c005fede72b8bbc9101d6f44448c01d71fe871e9b636db2b4d7312a3
0918363bc6ea19e6150a194a1454a05c3125f2f8b9c0cb5d0e955286c4142362138db8f940878b7774560d87702f4c8f6f97c661d6705f06b323339980bfcea461f4823844c44a3b916a9553c15529aef26fca8a78ab9f1eca15536270474fd4afa486a7c6fce76975269cb89c8ee57f24e3d0d99c538e2c93010d2aa9d1b4
9a1a35caaa5020c8455417e8f82423a6acb0ae32532e033a36d4a0473377547ad7f5adce226fdeb4f79f4ac582cd49d952869dd3acdc956455655ba9224af46ae98e3675dc2cd6dd984cc0a9abe9f8fdaf146c3d9a2a6974c8f50752d0b1810635caaa9c6edfe7d8608e4b34223cd6801bf7f5b8704b8bfda7d2ac6ebed5bc
ba9ba8f5ce5cd75a55d9e7ef2dc7b7fdbcd1bebe067211f9efaa94a17e2535ea5752e3e4e5747cfd733c6e3e74ec57fc0ac55d31fd536f942f2e7d74bf1f37245a55a9f47e69574cfbc447f4db4e80b71c1f367547e7861afcb62719337e4b60459f1911b106fcb03651d2dfb8ab65f8a68f377a347717bc41be7933af5e46
85ea655418dcd1135f2d8e9354b937f19778ec991b24eaba6230db414c8211350784bff66f7a830949a926a4694d48b753058db7871c6deb8a0be69f36254aeedc5138588135dffa2324bf75bbba465915fe981d88c133631cb6154693f7d5583cdaefe5d81952c42719b1769ff4e6869d1a6a306b988fd9f12e2c1525f56b
ed811a6554e835391a61519c5eec4df37e4f4462b2f89b655e7f17ac9ae08f32214aab3fb37841057e9f1a80f14be2443741bd7257873d2753f1414d37a7daff0e5bf96730020f9ee95ffbef49a401f14946bb853200746fa2111528f7c2f4382cb158e1dd424afc393bd0ea507ef54964f9d7fe685ddbf14ebec2c10a2cf8
c2ba50069e8fcd21f5a9b55f6b0fccfddcd7aa507e55e9a24a6c9f1988600e44f49ac83823361c4891747eae9b6c5b28bfe02207a67fea831ecddc45ffcdb2edce57119fabe7fcf3f19463a8c8994b361f4e915471e4ae9661c9583ff87ada67172b5c80b9237ced72f2dbd3cc213e5675ce7961d321693dc86a945161423f
6fc8ecf4ea9a3fd005cbc6fa89ae63c80dd6ef4f96d464f0fba13e78b7907dcfcba983bc459feb67ae6b9dae354fae0ee6af7a7a890eceddc7a5952dcf18e223a9099e186a5719168f769c10295e50815a360c957afb911eb71f89af17f0f19463d1685fbb0f0959f15d578cfdd88b89fc3fdb8f8a3fd72b977445bbba1abb
7f0757a50c9306881f2e76f709e7ea6c956b83b95935b5e8d7a5279106dc921020a58a28d1be9e2653be77487e05ba35d138c43e6c5ddbcda627d7c3e7a45d4c03da7864da04027d5ab923af3f8b346e3ed449aa681ed7cbcb6e6f2f6faa5e4685f74b8bab4cdefbaf738d73922b83b9745125e68df4137d425db8296df094
e15d3c33ed640580211d3d6d2e5fb5d793a62dce4bd8af9e1a19fab676cfb4dfe2aa946170478f5c1fccff5e117f4c8a042b50edbdcc6daad656e4d3f8f57b3a4995958e2ed7cde7f25e88121ba60408b6237ed3c53be24f560f37195a66720d71812017542fe39aed03ba942c6c5bb9e2a53be29fcc9a557783977be63e47
74a8afc1c465f1b9ba13ca996be2cff5001f39166d49ccd4ef1319272e6c8d26e0e21d1d6a97778e36cdb92a983b35d060fa601fc9b322dc7f2abe3955f532aa2c9916a7767955b607b3d4819f5ea537004f22c5170fd52e97f9179cafa71cef852871f9bfdcdb2dfcf623f1bffdec752dce5e779ca1386f3d6430e72845f3
29f0552f2fabdb3a3e9630ed5456f542aa95cdbd9d5ce48046657d714a589441f41c8859b95f6b9653e5ea607e109e73db743f8e749ef6e84e1bcc6e2a19ea5554a173237734795f2dba275246a4f44a2b98276b2a90f207656f45958b8bcca672f49804f117918b1cc8179835bfb74060eead004cd39a7274396d1883397b
c86580e7ffca19d5ae32a85d655029813cfe2ec8e3e782607f1704073c9f0ebd4c88122a3b4d55ffe6cccf42de9c3035b3f879ca2193c121a699caec7deaeb29cfb22eb77edeb93798737af7f49474e7a91c70d8600ef491237475b0437c17ad4e428878644d302b143278b8c9ec32896c76d04918d6c4c733eb1a0ff97ae6
dea6fde9397c1c6a671af724577730114b4a878eac1a64dd6492f6d4e96894121e09b2f27726a51a73ed796eaf37ccec7ca36630e72252c681c8cc59a35f159f64945479c67d2a4e6e9b8df955525b2b39dcf777739e6466308be0ef25bedc313c366bd232a78f88e62fa12c372b2ba59ca902c99a27e6cc6e2b9eb9d7a9f3
c41983598402125a5a4869a06f8b935772f68494c1fe2e92da7b9fc9a2f6b2a7af6973f5b95e3438e736d40ac9af749ae3a000d9f5643d96459d3e4e5eced901a270010a0429705fe44c22472fa4a3611575a67ea7d47493a46ee2cea8782185e89eae9eee726c98e20fb9cc318a10b2aaa92a83d941542821fe4efc2cfaf9
9c7dd5cb645e8788f018030e9ecdf9a369552ce12a3a98779f48c5d7bdbd327564bdcd875324b5c07146d5de73c5669143b126261ba1d303554b2919122ccac87a95df7595d49962d6dacc1d3f60f91fc94e1120954b8a1f04292cca8075fb5332edbb184dc0926d9cf95c6a8fd2357b9319100ce6ec11e4e78272ef880f91
9357d271e074e63cd1de0bd363e52ee708904655d5926e78f337265a35a3b2182b7725e15e1827682d1cac40f962e2cff56d475270e3be8e21c1a28cecd1b2965ad228739ffd188b5db36c9f56ea557a03307476acd334a42f94e7f90d4fec7e0d8f31e0939931583331c0ae0345dd7ca8c3b45f137892ff4fc7866ea28f89
c1080c9b138b1d3303a1b16373bbebf775f8efb1f81b65487e85e8497919cc4ea473430d66ad4d844ee4f4eaf14946f4991a8ddfa706d86500769309f86a511c426f3957e554f7a61a4937bcbf43d3316e711cbe1bec63d3f8272f44c619d17f7a4c8eeff5664f5d1ab963f6ba44c427897b3bb9764f8761b363ec36bbceb1
d074f49d1a2da963d16f13fc9d2a98599421521e3f17b4a9236d74ba3b8ff5683122d2e6a65ee95a1386cf89c5bafdce579ed7a9a1467237e8b5fb92f1d1b75136176bfcf7448f0e632371f7098b305ee5a991a17f1b699306ecfd370d5dbf8942948d9d810e9c4e43ef29d242b948b002f52bab9dea1830982518dec5130a
89338744c41ad0795c14262c8d47448cf4ce0b47cea7a1c9f0086c3d92e294fbd44d25c3e08e9e92ffee58683a1a0f8fc09abdc9a2df625e48d39ab0786b129a7f1ec1503663507b0fe49738d2dee96b5ad4fd241cab7627432ff19824a59a3079453cfa4e8d96fcf632b2bba75dde9e58949143152ba040af16ee58fe87b4
ca379dde84e57f2461edbe64b4aee386fa95d4a8535e057fefb7cf26a3e9f980df7f87a663eb911449b37ce454fddbb863cdbe643c782a2d249f46193066611c166c4a44dbba1ad4ada842d552ae19be4ea7694db8704b8b03a7d3b0ed482a22620d3ca105b8ab6598f6890f7a4f8996f477f149468c5b1c871fd727a06303
0d1a5755a36c31d70c6752d7e94db8785b87bdffa662e3c114abbadebf5fda15edeb6b9c6eff339825faf2232f1c389d8a87560c289ea63561d3c1146c3af8fce9d7d7530e7f6f397c3de5484e33213ade88e804a3e4a78d9cce5529c3aca13ee8fa4d9455d33a3d8a3060c1e6442cd89c088542063f2f39fcbce4f0749321
2ec988e87863ae1e03c35a4dde57a36f6b0facf8437a2ba0c838237ede96849fb725c1450ee4f57781b7871c1e6e32c42799101d6f407482d1a6616bdd5432cc1ceaeb5483173198ade4a99161c1177ee83036d2e6418462138d884d646000cf670ef9b4a327166eb6ad0db85e6f42448cc1aa62237adb84be5eb8f29fd6a6
aeea06e3f399e69fd8791c92c903bd51bca0734618cb98ad50b9a42b660cf1e58eb0b3311f7ba1797535778403512a64f875bce3b57818d8ce031f367577dafdce60b652f7261a7cd1c32bdb3e5fed2a439910e7ea0aeb22077e1ae527a947a0bd952ca2ccb03c3437f3f69063fd9400942ae218e75baf96ee98d0d7dba9f7
3983d90623ba79625c2f2f64f5182e4a850c4bc6faa1e2bbae4eb74f356a19364c0940dd0a593fd96c487e05d64ff2cfd4f13872aa006f3976fc108886d9dc2cad5f6b0f4cfdc40732273f440c661b0de9e48979237ceddaeb4988a7bb1cabbff547e3aacefbcaaf513f7f7deede24eb6adb2b9470c5d6198108f273e1496d
86bb5a8695dff8616827cf2caf7053bbca306f842f260ff476caca3e067326e8d840835db30333bd682124bf02dbbf0f409d6c789acc6a2a5719660df7c5bc11bef0cee47914dbd675c3e6e90108f4e1e560894221c357bdbcf0fbd400bc933f6b2ade2a9774c581f941e8d450936bf633cf443b79b79012bb7f0cc2e481de
769f295b2e7b5eaeb66f6e104a16ce5d432c766aa8c1b19ff3a06b638ddd3b11f878ca316fa42f167de92769aa2b7ade8ae6d082204cecef9d6937b47c012e983ddc17dbbeb7ef983339e206c853cc7e5ce4cfcbc0ba3771c7bafdc958bd2719771eeb6dda5ea3aa6a8cfec8cb612a5eb24380b71c733ef3c5675d3db1645b
12b61f4b153d8e4346bcdce5f8b8853b8676f2c8d1532939c2d3f380b61ee8d5d21d9b0fa760edbe145cbcadb5a96d3200547cd715dd1a6bd0b9a126c74f106b2dd9e3ddf90bc80c7894151ff624d220ba0bac52814c1d6c3eab5cb9abc3fe5369387d2d1d176e6a91942a7cd6baab65a85a5a85dae5556857d70dc101e6cb
3cef3cd6e3a988b9ff0ae571416111b3b0188cc0894be2666091cb815ae5b2e7f8e8f4261c3e978ebf2fa6e3d4d574dc7ca0b3d8a63c38c00535cbaad0a0b20a2d6ab8412d70c19fbc920ebd5e5c808869c1f12cda80eb2287c6ccebef22fa261c9768c40591835af978c8b3a4b2f8718401fb4fa5e2ec0d2dceddd0e27184
e5f333c05b8ef2255c51a7bc0a0d2aab51ac40e63e2ffe7b255df4581cd5cba8b2e36dea499606333def11f5e0a91e89294624ff2fa4d52a193cdc64289c572118c49431bd017812a94758a40149a9a697632d78bacbe1e32143483e053cf9649c2dd2b5263c0c37203cc680943413b43a136472c04b2387b7871c45825df8
d6c260262272fc60e6ad8a88c8c13098898818cc4444c4602622623013111183998888c14c44440c662222063311113198898818cc4444c460262222b3143f1e93072f3fa1e39e2022720001eec8cb2766222207c3602622623013111183998888c14c44440c662222063311113198898818cc4444c4602622623013111183
99888818cc44440c66222262301311390385a37f417f6f3f542ff73eca152f8b90fc4510e01b002f772f188d06c4c4c7222621165171d1b8f5e036ce5dbf806b77aff3a8925370552ae1efed9fe13213806751cf2c6ec3c7d31b6e2ab70c9725a7a6202139813b9ac12c8e46ad41d7a61dd1a56927542b531532994cf4df86
453ec51fc7fec4aa3fd6e2fabd1b3cc29463552f5b0d3b7edc94e132bd418fc086052d6e63f68819e8d0a85d86cb56eef80d23e78ce18e66300b53b9aa30a4cb2718dc6520fcbdfdacda46bec0600cead81f833af6c7817f0f62fa8a9908bd7989479a88720c872963ae53b1164efc7a18e3078cb53a94dfd4a47a231cfc79
0f668df80e1e1a0f1e6d2262308bfa027239c6f41e856d737e4748fea299b2fd7eed7ae3f0d27d2853ec3d1e712262300b51b828307ff46c8cedf3055ce42e99fa59c50a8660dfc29d6858b51e8f3a113198cd85f2aac9cbd0a345b72cfb4c8d5a8375dffd86a6351af3c81391c3ca96ca3f994c86f9a367a365ede6a2ffe6
f6c3ff70e146289e4587233c261c29a929502894080ec88312854ba07ad9f711e0e36f713b2aa52b564e5c8256c33be0c2cd8b3c03c8a985deba047737f70c975df9ef1a771083f9ff7dd2a93fba37ef6271bdd4b454fcfac71aacdcf91b6e3fbc6331eceb54ac85c19d07a259cd26169f9cd74c5b891abdeab31d2739b59f
362cc64f1b167347e430595e9451ae78194c1c34dee27a074f1f41958f6a61dc8209164319004c26138e9dff07ddbeea894e5f7e8888d848c1f5f3050663f2e0093c038828773f31cbe572cc193513ae4aa5e07af3d62fc4e4a5d361341aadfa9c83a70fa3c18066d836fb7794285cdcec7a3d3ff8102b77acc2c55b97adfe
4dfede7ea859be3a4a152d8940df00e4f1cf03b5ab0a5171d1888c8dc29388309cbf118a0b374261301ab2643f17cd5704cd6b3541f182c510e01b004f770fc426c4e1e1b347387bf51c0e9d398a94b4148bdbf1f5f241fdca7551fedd722898a700fcbc7da1d7eb11971887074f1f21f4e645fc137a027189f159f2bb0ae5
2d88da156ba258811004f90721c0db1f7a8301113111888c8bc2ad0777f04fe809844787e7d80bd255a9844cf6fc7949a910be3c55aeaad7febf4eaf7beb9a512a9490cb337efe32180cd01bf476f9de250a1747b31a8d51347f51e4f50f020084c74422222602d7efdec0b1f3ff2026213653f69946ad41cdf2d551be4459
04f90622c83f089e1a4f44c545212a2e1a0f9e3ec4c94ba770e5ce550673463a356e8fcaa52a5a7cf59af8f3549b3f2b2cf2295a7dd601fb17ed42917c85cd167f8ceb3b1a5dc77e2c69db32990c8dab35c4a08efd50af721d285c2cefc6c8d8286c3db41d8b372dc383a70f25ff9e2aa52be1c0e23f335c3676fe782cd9f2
0bde2910821f464c47832ac22d4f129213f0cbb69598bd7a7e86015d245f618ce93d0aed1bb6854ae92ab82dad4e873dc7f761eeba9f2477e45935f917b4a9f7c15bff9ea64d477093222fff7ff39a4d31bcfb60542ffbbec55ea046a311272f9dc2cf9b9761f7f17d926fee3d5a74c382b13f66b8ec5ed87d54ea5e43d2f6
f62ddc89f7cb54cd70d9a425d33077dd8237d6df850aef96b37ce1ba28f0ecc0fdd7feaddfa44fb0f5d08ed7feede771f3adeaf957f5bd2ad8bfe88f0c974d5ef61d7e5c331f00f0419de6f8badf18942a5a52f0fba6ebb4f8e3e82ecc58391bff3dbe6b973c2955b4248675fb146debb78246adb1b8fead07b7b170e312ac
dbf3fbcb1bd281c5bb50a574e50cd7afd8bd3aee873d70ee6096c96418f1e130c175fe093d81894ba6daed332363a3d079f4876855a7a5e07a6e6a37a4a6a58ada66d962ef61cea8efcd1e4c73027d0330a8637ff46bd71b2bb6afc2b4e533ed5abeddbc6653ac9cb414ea379ea232e2e5ee85911f7d8636f55ae3c3713d71
fbe17f2f970de8d01753067f6b31905f7dc26b5bbf15dad4fb00bfee5c8d710bbf455a7a9a5d7e53905f10167d35178dde6f20e9adac56851aa855a106ce5e3b8fcf677d89abace4b2bb20bf20fc326111ea54ac256a7d95d2159d1a7740abba1f60dc4fe3b172e76aab3fdb43e3818983be469f363dcdbe0d987baa9ff7e5
2cf46afd11fa4ffa14f7c2eef389b966f9ea2859f45db3cb6313e23070ca10ab8b2fccb9f3e8ee5b4f25d6fab4f3004c1c34de62518ca5279d811dfba159cd26e8f3ed40bbb40c6958b51eea55a92b3a4c5f28563004bbe66d45b3216df0e0e9434c1f3a099f741a60f58db74fdb9e2859f45d741edd03c9a9c936bf1a6f9d
b501f983f259bd8d2aa52be1af9f7763e4ecd158bf7723d3d44eca167b0f8797ee45bec09a4ecdcd000013214944415460c97fab765561cea899f0f6f0b6eaba7ca74008d67fb70ac50b15b3fafb572a5901fb16fd81f6a3ba3aec3eceb2cabfce4d3a0a2e5fb469099e8a182d2b5b76925c8e1f3e9f8ee94327db14caaf2a
1c5c087fcedf669736d54d6b34961ccaaf3ef9fc3a6919c6f6f9c2ea507e558d72d5cc160588bf79b960fb9c8d3685f2ab41b070ec5c7cda7900c83eda3768635528bf6ac2c071685cada1e49bf5ee9fb6d914caafbec16efc7e0dfcec34fc438e0de64655eb9b5d969492845fb6ad74d81371c2c071e8dfbe8fddb7eba676
c39aa92b24bdaa6786f225ca6274af9176db5ebbfaad6dbae1285c14080ec86bb7ef2393c9306dc824b4aad382a9ea20643219be1b36054a85b8071d0f8d07564f598e20bf20bb7d877c81c199320c448e09e682790aa0409efc6697ef3db13fcb6af6a5ead1a21b3eeb3e44f4fae93a2de293c4971d2b154aac9cb804ef14
08b1fb774f494bb1b948e185346dbaa432f131bd4765ea71494a4912d5b2e4d520583076aec35e88cec06834222e311e3abd4ed4fac50a86a08b8537e917c76ec9d73f09b6b07a536a5aaaa4ebd0d164491973a910e11adba3e7fe71c89d53be4459cc1935d3e27ad7ee5ec7b2ad2bb0ffdf83088b7c0ae079a558d96265d0
b67e6bf46bd74bb0d6d8d3dd13cb262c42934f3eb0b949dded87773067cd7cecfe67dfcb20f5f7f643b39a4df045cfcf51345f11d1db8a4d88c39c35f3b0e5e0f697c54c9eee9e6851ab29c6f6f942705b954a5640f142efbc56b1688b749d16ab77adc5cea37fe2f4d5b348d7a6bffc3eb5cad74097a61dd1ae7e6bc1561b
de1e5e5830f647b41cd6ce612fc84d7f6dc1c94ba70000f983f265d86ae545082ed9b2fcad639f1d61bc6ad75aacdeb51697ef5c85dea0874c2643f9126531b0433f746bd659f098b46fd8066bf76c10fc8c0f9b77b5d84bd86432e1cf7ff662c3be8df8fbfc8997e7be52a144e99092685eb3290674e86bb7912b9d22988b
0417165c7efaea59877cd5b2d4e65a6fd063fca2c958b675c55b81aad5e970eefa059cbb7e018b362dc582313fa2d1fbe68b732abe5b1ebddb7c8ce5db7fb5fa3b9fbc740addc6f67cebc9363a3e06ebf6fc8e1d4776e1f719ab51ab82e5265f8fc39fa0f5e71ddf6a2e94989c888dfbb760eff103d8326b3daa94ae64761b
cd6b36c5ed87b6f73a3b75f90c064e1d8287cf1ebdb52c3139117b4fecc7de13fbb1a8f412ac9cb854f0edac46b96a6856b309f69d38e09017e4a28d4b5ffeefba956a9b0f669311e316646f07a9b4f43474ffaa178e9c3bf6564886debc84c1df7d8633d7ce61cec8efcd6ea376c55ad0a83566df7e5c954a7cdd5f7830ff
a8b868f49ad01f272efefbd6329d5e878bb72ee3e2adcb58bc6919beff6c2aba35ebecf0c19c2545197edebe82cb1db143408b5acd50a96405b3cbb53a1dba7fd50b3f6f5e66f129f759d433741bfb3136eedf22b8dec88f865b5db998969e86c1df7d2658dc909c9a8c41d38622ed7f4f9b42867d3f52b00d67427202064d
1d2af8da5aa144399b8fc39ee3fbd07664e70c43f94d67af9d4793c1ad70e791703bd94f3bb122d01e46fd38f6ad507ed3ca1dbf09aea352bae29d02e68b97dad46b2d58df1093108be643da6418ca199db39f4e1f8ef9eb1731980108bec6eb0d7a2424273adc8e19d041b8b26ff4dcaff0d7a943a2b7a737e8316ce6089c
11783bc817188c16b59a59f57d771efd535463f8271161387af698c527544b171c00dc7d720fc7ce9b2f862a2ea14c3023d7efddc08029435e165b88f12cea197a8eef2758fe5cbb624d787b7831596d70ebc16dd14d1057ef5a27fc469dcffc1b75cbdac2d7c390ef3e97dc6165d2d269387cf62883d96832df36592e9367
fa58cc5205f906a26ec5da66971f39770cab76ad95bc5dad4e87213346083e61b7addfdaaaeffc4fe809d1ebfe7bf9b4e0f27dfffe257a5bc7059e546c6dee367aeed756555e5ebf77030b7f5f6276b98bdc4574c708cad8eee3fb60329944ad2b74f37e7e9e645cf42497cb51b792f9ebf0c4c57fb1f7c47ee979643462ec
fcf176ef3391e3823925d5fcd38b5c2e77b8b684b52ad410ec5134f3d739566ffbf6c33bd8f646b7d957d5a9584bd2e4b3af6e57acbb4fee092ebf744b7cd7eaff1e99afdc3337dca418a72e9f9174b379d3a24d4b90aed39a5d2e74c19365e7af5f10bd6e545c346213e224bf519779a7b46065dd8a1dbfd9f4c47fe8cc91
dc1dcc11311182cb8303f238d44e292b300555646c144e5d3963d3f6fffc7bafd965013efe56b5e18d4b12dfdcd05233a247e14fc47fae40334795d255743bd53759f324f4e6f73a2d709c0a071762bada404c99bfd8f5cd0d2350306f01bbbd2566c4918b33b22498ef5928fbac5da1a643ed9442c1e6a7853f7bed9ccdaf
40ff5a08766b4223292549fc1b8c857141a2e3a2edb62d296319bcf6447623d4e6e3784ee0a9ce5fc4a40a64deb3e80849eb0b554aab55ea8c8f91b7bfe00392ad8d062edc70dc8932b22498afdcb92a581ee568533d796a3ccd3ffdc746d9bcfda8d828c170f7f6f096bccd440915a82693f08d254d42659ba56d59bd8f24
dc1ccc5fbc91826f265972813958fd89bd881df4ebe5392530b095b9d119858a38e312e36cfe0dd1f131b93b98a3e36370f3fe2db3cb6b94ab2658339bd584ca78e55694ffbe1d66269860fe46654d93397b8de806007a913db73293d88a25e1df61be92d59a8e3cae0ae9e3918819ed2f274ad7a54b3b3fb5e9923f432750
47a0b3c339aad3e91c76ff66d958194235fd4a85125ff71bed303b2551a05820c837d0e6edfb7bfb09b644b15737ea9c2cd0372053b761aeb84668e07873afdc82c1ac7273cae323b538cf9a1badd0c0fabe5ebeb65f870e5c9c9565c16ca973458786edcc0e289ed51e0b547e552e5dc9ea72d3172a96aa20b85c4ae59bb3
2a5fa2accddb2857bc8ce4a29234adf9370f0f8d87e41633012ccbce94a28640df0078683c6cdabe50c7965c13ccd7ee5ec7f1d093e6bf885c8e559396da755431e079531c1f4f6fc1ffde7c7abd76f7bae085267590fc3735afd954f095efbe030fe09d559a546f64d3dfbba9dd04bb9edf7b927185b45065a64ae98a3cfe
79249f7b649d7b02cd3a152e0a54b3f141ae4e25c76dcb9ea593b1cefa6daee0f2bc0179b166da4a78b9dba75756832af5706bfb25dcdb75c3ec7f8797ee7beb09f8f8c59382af5ea33e1a6ef577ca17182cd857fff49533d03a70d95756a953b196c569c8840c68df47b01db5b99e8d968a918a491805d01e4ffdb9d9ed87
ff098ed1dea36537abb7edebe583b6f55a31985f5c0c7b8eef135ca752c90a38b4740f8a15b46d18ccd6755b62dd77ab2c7672f8fed7d96f55243c0e7f8273d7cf9bfd9ba6351aa37d833692bf934c26c3ac11df0956086d3ff207afc8ff99317caa55130014ca5b10237a98bf796a753ab3632b589a8f514ac794c6d51af0
20dae8eff3c7cd2e6b53ef03ab6f7e5ff61c69735188d30433008c99f78dc5717ddf2910823d0b76a243a37692cbf43cdd3d31f3b369f875d2328b35e257ee5cc5a6035b335c66a957d14f63e6487ea29b30709ce05818f14909d8f2d7765e8dff53a57425cc19355352977d6f0f2fac9afc8b6011c2e13347cc3e1987453e
156c0ad6a5694751378b20df40f46afd310fa28d761cdd6576998bdc052b272d859fc48ac0b6f55be1934efd1dfa776779303f0a7f8ca1334658aca50df0f1c7f2098b7160f19f685eb3e95b53b5bf49ad52e3c3165d71eab76318d0a1afc50abab4f4340c983ac46cb3a9cd7f6d131c1cc5ddcd1d3be76e463b11635bb8bb
b963d157f3f0f9874385c37ec322bb4ed0ea0c3e6cd1156ba7ad1475f1bd5320047b17ecb438cbf4e2cdcbcc2e33994cb878fbb2d9e585830b61fcc07182dbf772f7c2aa29bfe498b17f1dd99ee3fb70e3de4db3cb8be62b827d8b76a178a17744bdb10eecd00fbf4c586cd5b0075949911d1ffac7b1dd98b96a8ea8592e2a
97aa88f5dfad424a5a0a8e9c3d865b0fef203c3a02f149f1f0f3f245bec07c08295004b52bd494f46af2f5c28982075ca7d7e18b395f61ebec0d660fa246adc1ca494bd1fbdcdf58ba75050e9f3dfadad356813cf9d1ba6e4b7cd67d88c54aa3db0fef60c186c5bc1233d0ac66135cd8f02f166f5a869d47ff7cad72f6c5a0
ec9d1b7744bff6bd2d3ecd1e3a731447cffd2db8ceae63bb51bdecfb66970fe9320879fd833073d58fb8f5e0f66b6f6badeab4c0577dbf44c13c0578e0ecc0643261cedaf958facd42b3eb142b18827f561cc69addebb061df669cbf7ee1b5072e7f6f3f34a85a1f43bb7e9263cafd15d9f5c13356ce82afa70f0676ec276a
7d8d5a8396b59ba3a51d3e7bd66f73b162c72a8beb1d39770cdfadfc01e3fa0ab7b1ae57b90eea55ae03ad4e87a8b828c427c523d037507453a9b8c478f4f8ba8fe0a03bb99d97bb17c6f41e8531bd4721292509cfa223603219912f3058f460494929491835678cc5f5b61dde89f103c709867cc746edd1b1517b44c64621
2a2e0abe9e3e08f00d30db8b8dacb7e5e076f46cd54370e80657a5127ddbf642dfb6bd909a968ac8b82824a726c3dfdb0f013e01563571cdced1e7e4d9b9c3c7fe34de624b0d7b9bbd7a1ea62dff5e52885b6a83fdeac9912f3018a58a96141dca3abd0ebdbf1d902dd302e5541e1a0f142b1882e2858a890e6593c96471f0
ff17c2229f62c5f655a2b61be81b8052454b226f405e867226311a8df864da308b83a1bde0a67643a1bc0551aa684904f90559ddef203b3b7a656b309b4c264c5bfe3d3e9d3e5cd2c49ad6eee441d38662ea2f33247fc7e13f8cb2d89ac4daefd477e2208bafd664fb79366ec1b7925abccc5e3d17cf049a6a51d67a121186
6e637bda7582d5d09b970447bd933230985305f30b1bf66d428381cd71eaf2994cd9feb9eb17d0606073d14fbe6f4ad7a6a3e7f8fe58b871895dc6700080fb610fd074706becfa7b0fafba0c9cba7c06110283108995a64dc790199fe367810abf8c44c7c7e0e3f1fd6cba384d2613761cd9c5836927176e5e44db119d04db
368b75fe4628da8fea0237335de6b53a5db6162dca1d65a7df7a701b2d86b5c5a06943ed36b3f27f8fefa2efc44168f2e907361715e80d7a7cb370223a8ffed0e240f3965ecb56ffb90e0d073517ec6198db85deba88bafd9a589cfd42c8a5db57d06c702bd15320bde9ecb5f3683faaebcb99cf25dd10d2d3d067e2402cde
bc9407d38e2edeba8cfafd9bdaf440b3e7f83eb41fd9155a9dce6ccb99e8f8e86cfd9d7247dae92693091bf76f41f55e75d1e3eb3ed8716497e451d3d2b4e9d8767827ba8efd18d57bd6c3b6c33bedf6940b00074f1f418d5ef530ecfb91b87ce7aae8bf4b494bc1fabd1b51bb6f230c9f394a7046077a2e3c3a1c6d477446
97311fe1ecb573920279d0b4a16838b0392eddbe62d377387bed3c6af76d889f372f1335d4a5c964c2d683db51ad675d3e2d679288d8487cfc4d5fb41dd11987cf1e155d49f7dfe3bbe83f79303e1cd71b09c909a85caaa2d9f2e71bf76f66eb6f948d1a5bb0eaf213bad38e7a1054ae2a542e5511efbf570545f31741fea0
fcf0f3f685d24581d4f454c425c623262116976f5fc1f91ba1b878eb72a69757bfaa58c110d4a9541be54b944391e042f0f6f086c2c50511b151888c8d445844184e5d3d8b63e7ff913c86ed6bfb41e98ae0c060b3cb1f3c7d28fa06e428db5a35f917b4a9f74186cb966cf90563e78f7feddf8ae62b820655ebe1fd325510
e013803c7e81d01b0c484c49c4fdb007b878eb328e9dffdb6e6f5c6ff2f6f042d31a8d51b57465e40bcc8720bf00a8556e888a8b42644c14febd7c0a87ce1c7dadf7a0ca556576fc97d88458c13253a1bf35994c167b2902cf2b27cd55902626279a1d2848e8b3a59e23c0f30e371ab78ca7904a484a101c49ce92e080bc68
50b51eaa94aa84c2f90ac3cfcb172e2e2e88fcdf3578efc97d1c3e7b0c67ae9e7ded3b8f1f3016233ffa2cc36d2edeb40ce3164cc896cc0b7087c1e183999c97d46026b21757a51297379e45905f5086cb87ccf81cebf6fc9e6dc1ccf63d44e4b0ba34ed088dc098d667ae9dc7d5ffae49deeed0ae83cd86b2dea0c7fe937f
65ebef66301391c32a5fbc1c067719687679524a123e1cd71b7f5f382e7a9b0daad413ec757cecfc71bb4c6d660b390f3d1139aa79eb170ad61979683cb0f987f5f876e0388b9d8d5c954a0ce932081b66ac169cbe2dbb8a30f8c44c443942444c04befa6902e67d394b30703fef310cbddbf4c4a1d387f14fe8093c8b8e40
747c0cd4ae2ae4f10f42b53255d1a25633e413a8a8069e4f92b1fdf04e0633119190df76ad45bdca75d0a1615bc1f57c3cbdd1a1513b7468d4ceaacf49d76931ecfb91564dd46b6f2cca202287f7e9f461d877e240a66ddf683462f0f4e1387f23d4217e2f8399881c9e56a743af09fdb16ad75abb6f3b4d9b8e7e933ec1d6
433b1ce6f7329889284748d769f1f90f5fa0dfa44f448f3467c9b5bbd7d16c702b879bd28d1d4c28db14c957d8ec145091b151781211c69d44197253bb6150877e18d8b19f600f45731e3c7d8879eb1660cdee0d6fcdf999ddd8f38f887234b95c8e1ae5aaa165ade6285fa22cca167f0f5eee5e6fad179f94805b0f6ee1c4
a553d87ff22f9cbc74caae63e8d83b98d92a8388722ca3d188e3a127713cf4e4cb7f7377738797bb2754ae2a984c2644c7c764ebd8cad66030139153494e4dced6d947ecf226c0c34844c460262222063311118399888818cc44440c662222623013113198898888c14c44c46026222207f27ffe3ed8687c70ee3100000000
49454e44ae426082}
\par
}{{\fs28 \pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \sb569 \fi0 \fs28 Institut f\u252?r Informationssysteme\par
\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \fi0 \fs28 Forschungsgruppe \ldblquote Parallel Computing\rdblquote  (E184-5)\par
\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \fi0 \fs28 Prof. Dr. Jesper Larsson Tr\u228?ff\par
\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \sb1138 \fi0 \fs28  }\par
{\fs50 \pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \fi300 \fs50 {\b Seminararbeit}\par
\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \fi0 \fs50 }\par
{\fs28 \pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \sb569 \fi300 \fs28 f\u252?r ein \par
\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \fi0 \fs28 Seminar aus Programmiersprachen{} \par
\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \fi0 \fs28 \ldblquote Efficient Shared Memory Programming{}\rdblquote  }\par
{\fs28 \pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \sb1138 \fi300 \fs28 {\b \ldblquote The Adaptive Priority Queue with Elimination and Combining{}\rdblquote } }\par
{\fs28 \pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \sb1138 \fi300 \fs28 Stefan Haider\par
\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \fi0 \fs28 Matrikelnummer: 1125543\par
\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \sb1138 \fi0 \fs28 \par
\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \fi300 \fs28 Betreuer: Univ.Prof. Dr. Jesper Larsson Tr\u228?ff\par
\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \sb1138 \fi300 \fs28 24. Feb. 2017\par
\pard\plain\s9\qc\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \fi0 \fs28 } \par
}}\page
\pard\plain\s3\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb240 \fi0 Main Literature Sources\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb60 \fi0 The following seminar report is based on the following research article:\par
{\pard\plain\s46\ql\fi-283\li283\lin283\sb0\sa120\widctlpar\tql\tx283\f0\fs20\sl240\slmult1 \sb50 \li600\fi-300 1.\tab
{{maxnames}{999999}}{calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014} \par
}\page
\pard\plain\s3\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb300 \fi0 Erkl\'e4rung zur Verfassung der Arbeit\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb90 \fi0 Hiermit erkl\'e4re ich, dass ich diese Arbeit selbst\'e4ndig verfasst habe, dass ich die verwendeten Quellen und Hilfsmittel vollst\'e4ndig angegeben habe und dass ich die Stellen der Arbeit \endash  einschlie\u223?lich Tabellen, Karten und Abbildungen \endash , die anderen Werken oder dem Internet im Wortlaut oder dem Sinn nach entnommen sind, auf jeden Fall unter Angabe der Quelle als Entlehnung kenntlich gemacht habe.\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb50 \fi0 \par
_____________________________________________\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \fi0 Wien, 24. Feb. 2017\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \fi0 Stefan Haider\par
\page
\pard\plain\s80\ql\sb240\sa120\keepn\f0\b\fs20\sl240\slmult1 \fi0  Contents\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \fi0 \par
{\field{\*\fldinst TOC \\o "1-3" }{\fldrslt }}
\page
\pard\plain\s3\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb300 \fi0 1  Introduction\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb60 \fi0 A priority queue is a data structure for storing elements with associated keys. The keys represent priorities. Priority queues can be implemented in two forms: max-priority queues and min-priority queues. The latter one is the form that is considered in this paper.\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \fi300 Typically a min-priority queue exports two operations: {\f3 add()}, for inserting an item into the priority queue, and {\f3 removeMin()} for removing the element with the minimum priority. {cormen\\s\\do5({\fs16 i})ntroduction\\s\\do5({\fs16 2})009} describe other typical operations of a priority queue like: {\f3 minimum()} for retrieving without removing the minimum-priority-element, and {\f3 decreaseKey()} for decreasing the key of the given element to a given value.\par
(\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \fi300 Parallel) priority queues are often used for resource management in schedulers, for event simulations, or as data structures in graph-algorithms (e.g. Dijkstra\rquote s shortest path algorithm, or Prim\rquote s minimum spanning tree algorithm) 
[{\field{\*\fldinst{\lang1024 REF BIB_cormen_introduction_2009 \\* MERGEFORMAT }}{\fldrslt{cormen\\s\\do5({\fs16 i})ntroduction\\s\\do5({\fs16 2})009}}}
].\par
\pard\plain\s4\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb120 \fi0 1.1  Prior Work\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb60 \fi0 The first parallel priority queues implementations were based on heaps and linked lists as it can be seen in the study by {ronngren\\s\\do5({\fs16 c})omparative\\s\\do5({\fs16 1})997} 
[{\field{\*\fldinst{\lang1024 REF BIB_ronngren_comparative_1997 \\* MERGEFORMAT }}{\fldrslt{ronngren\\s\\do5({\fs16 c})omparative\\s\\do5({\fs16 1})997}}}
], parallel priority queue algorithms based on skiplists were proposed later by {shavit\\s\\do5({\fs16 s})calable\\s\\do5({\fs16 1})999}. This first implementation deals with bounded range priority queues as found in operating system schedulers. Such queues provide a fixed range of priorities. The algorithm uses coarse-grained locking for synchronizing concurrent {\f3 removeMin()} operations and is based on the concurrent skiplist by {pugh\\s\\do5({\fs16 c})oncurrent\\s\\do5({\fs16 1})990} as described in 
[{\field{\*\fldinst{\lang1024 REF BIB_pugh_concurrent_1990 \\* MERGEFORMAT }}{\fldrslt{pugh\\s\\do5({\fs16 c})oncurrent\\s\\do5({\fs16 1})990}}}
] 
[{\field{\*\fldinst{\lang1024 REF BIB_shavit_scalable_1999 \\* MERGEFORMAT }}{\fldrslt{shavit\\s\\do5({\fs16 s})calable\\s\\do5({\fs16 1})999}}}
].\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \fi300 {lotan\\s\\do5({\fs16 s})kiplist-based\\s\\do5({\fs16 2})000} proposed a general purpose priority queue based on {pugh\\s\\do5({\fs16 c})oncurrent\\s\\do5({\fs16 1})990}\rquote s concurrent skiplist. Each element has a flag to mark it as deleted. A delete pointer points to the current minimum priority element. Each {\f3 deleteMin()} operation traverses the skiplist until it finds a non marked element. The element is marked and afterwards deleted from the skiplist 
[{\field{\*\fldinst{\lang1024 REF BIB_lotan_skiplist_based_2000 \\* MERGEFORMAT }}{\fldrslt{lotan\\s\\do5({\fs16 s})kiplist\\s\\do5({\fs16 b})ased\\s\\do5({\fs16 2})000}}}
].\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \fi300 A lock-free priority queue based on a skiplist was introduced by {sundell\\s\\do5({\fs16 f})ast\\s\\do5({\fs16 2})003}. They use different atomic primitive operations like Test-And-Set\~(TAS), Fetch-And-Add\~(FAA) and Compare-And-Swap\~(CAS) to make their priority queue lock-free. For deletion, they use previously unused bits of the pointers in the skiplist to mark the node as deleted
[{\field{\*\fldinst{\lang1024 REF BIB_sundell_fast_2003 \\* MERGEFORMAT }}{\fldrslt{sundell\\s\\do5({\fs16 f})ast\\s\\do5({\fs16 2})003}}}
].\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \fi300 {shavit\\s\\do5({\fs16 e})limination\\s\\do5({\fs16 1})997} introduced the concept of elimination. This technique allows opposing operations to be coupled together by exchanging data via a small elimination datastructure. The distributed datastructure remains unchanged 
[{\field{\*\fldinst{\lang1024 REF BIB_shavit_elimination_1997 \\* MERGEFORMAT }}{\fldrslt{shavit\\s\\do5({\fs16 e})limination\\s\\do5({\fs16 1})997}}}
].\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \fi300 The paper by {hendler\\s\\do5({\fs16 f})lat\\s\\do5({\fs16 2})010} introduced the concept of flat combining. This concept is the opposing strategy to use fine-grained locking to keep the critical region small, as it uses a global lock on the datastructure. All access requests are combined and executed all at once before releasing the lock. The benefit of this approach is the reduced synchronization overhead and the reduced traffic through cache invalidations 
[{\field{\*\fldinst{\lang1024 REF BIB_hendler_flat_2010 \\* MERGEFORMAT }}{\fldrslt{hendler\\s\\do5({\fs16 f})lat\\s\\do5({\fs16 2})010}}}
].\par
\pard\plain\s4\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb120 \fi0 1.2  Contributions\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb60 \fi0 {calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014} developed a priority queue based on skiplists. They utilize the skiplists {capability for operation-batching and disjoint-access parallelism} 
[{\field{\*\fldinst{\lang1024 REF BIB_calciu_adaptive_2014 \\* MERGEFORMAT }}{\fldrslt{calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014}}}, 407
].\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \fi300 The elimination algorithm allows {\f3 add()} operations with keys smaller than the current queues minimum to eliminate with {\f3 removeMin()} operations. The idea of aging operations also allows {\f3 add()} operations to participate in elimination(if the key is below a certain threshold), even if they are not allowed to eliminate yet.\par
{\f3 \pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \fi300 \f3 RemoveMin()} operations are combined and delegated to a server thread. This thread is operating on the separate first part of the priority queue and serves every {\f3 removeMin()} and {\f3 add()} operation that is not eliminated.\par
{\f3 \pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \fi300 \f3 Add()} operations with keys over the threshold mentioned above do not use elimination. They are inserted into the skiplist directly. As inserting elements sequentially would be ineffective the skiplist is split into two parts. The first part is only operated by the server thread. The second part is accessed by all threads in parallel.\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \fi300 This design reduces contention through batched sequential {\f3 removeMin()} and {\f3 add()} (with small keys) operations, by using elimination, and by using parallel {\f3 add()} (with big keys) operations. \par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \fi300 {calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014} also implemented the algorithm by using hardware transactional memory instead of locks. The goal of this approach is to further increase performance and to simplify the implementation 
[{\field{\*\fldinst{\lang1024 REF BIB_calciu_adaptive_2014 \\* MERGEFORMAT }}{\fldrslt{calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014}}}
].\par
\pard\plain\s4\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb120 \fi0 1.3  (Hardware) Transactional Memory\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb60 \fi0 {herlihy\\s\\do5({\fs16 t})ransactional\\s\\do5({\fs16 1})993} introduced the concept of transactional memory. Transactional memory allows lock-free implementations of datastructures without having to worry about synchronization. It {allows programmers to define customized read-modify-write operations that apply to multiple, independently-chosen} sections of memory 
[{\field{\*\fldinst{\lang1024 REF BIB_herlihy_transactional_1993 \\* MERGEFORMAT }}{\fldrslt{herlihy\\s\\do5({\fs16 t})ransactional\\s\\do5({\fs16 1})993}}}, 289
]. Such transactional memory can be implemented in software or with the assistance of special hardware instructions 
[{\field{\*\fldinst{\lang1024 REF BIB_herlihy_transactional_1993 \\* MERGEFORMAT }}{\fldrslt{herlihy\\s\\do5({\fs16 t})ransactional\\s\\do5({\fs16 1})993}}}
].\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \fi300 Instructions as the Intel Transactional Synchronization Extensions (TSX) 
[{\field{\*\fldinst{\lang1024 REF BIB_intel_corporation_transactional_2012 \\* MERGEFORMAT }}{\fldrslt{intel\\s\\do5({\fs16 c})orporation\\s\\do5({\fs16 t})ransactional\\s\\do5({\fs16 2})012}}}
] build ontop of the concept of transactional memory to provide hardware assisted transactions. Threads are allowed to execute speculatively in parallel on the shared memory. In case of a conflict only one thread succeeds and all the others have to rollback and retry their operations 
[{\field{\*\fldinst{\lang1024 REF BIB_calciu_adaptive_2014 \\* MERGEFORMAT }}{\fldrslt{calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014}}}
].\par
\pard\plain\s3\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb240 \fi0 2  Design\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb60 \fi0 The priority queue implementation by {calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014} exports the two operations {\f3 add()} and {\f3 removeMin()}. It is based on a skiplist which is split into two parts as it can be seen in figure\~{\field{\*\fldinst{\lang1024 REF BMfig_pqe \\* MERGEFORMAT }}{\fldrslt{1}}}. The elements in the skiplist are buckets having associated keys accessible via {\f3 bucket.key}. {\f3 RemoveMin()} and {\f3 add()} operations with small keys are served by the sequential part, while {\f3 add()} operations with keys over a certain threshold are executed on the parallel part. The last element of the sequential part is referred to as {\f3 lastSeq} 
[{\field{\*\fldinst{\lang1024 REF BIB_calciu_adaptive_2014 \\* MERGEFORMAT }}{\fldrslt{calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014}}}
].\par
{\pard\plain\s31\qc\sb120\sa0\keep\widctlpar\f0\fs20\sl240\slmult1 \sb300 \fi0 \par
\pard\plain\s30\ql\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \fi0 {Figure {\*\bkmkstart BMfig_pqe}1{\*\bkmkend BMfig_pqe}: Skiplist design 
[{\field{\*\fldinst{\lang1024 REF BIB_calciu_adaptive_2014 \\* MERGEFORMAT }}{\fldrslt{calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014}}}
].}{\field{\*\fldinst TC "1 Skiplist design 
[{\field{\*\fldinst{\lang1024 REF BIB_calciu_adaptive_2014 \\* MERGEFORMAT }}{\fldrslt{calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014}}}
]." \\f f}{\fldrslt }}\par
}\pard\plain\s6\ql\sb240\sa120\keepn\f0\b\fs24\sl240\slmult1 \sb360 \fi0 Add()\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb60 \fi0 A thread executing {\f3 add({{\i v}})} on the priority queue decides to insert the element concurrently into the parallel part if {{\i v}>{\f3 {\i l}{\i a}{\i s}{\i t}{\i s}{\i e}{\i q}.{\i k}{\i e}{\i y}}}. Otherwise, the element is put into the elimination array as and add request. If the element becomes eligible for elimination ({{\i v}<{\f3 {\i m}{\i i}{\i n}{\i V}{\i a}{\i l}{\i u}{\i e}}}) the operation can eliminate with any {\f3 removeMin()} occurring, otherwise the operation will be executed by the server thread 
[{\field{\*\fldinst{\lang1024 REF BIB_calciu_adaptive_2014 \\* MERGEFORMAT }}{\fldrslt{calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014}}}
].\par
\pard\plain\s6\ql\sb240\sa120\keepn\f0\b\fs24\sl240\slmult1 \sb120 \fi0 RemoveMin()\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb60 \fi0 operations try to eliminate with an {\f3 add()} operation from the elimination array. If no operation is available, the thread writes a remove request to the array. It then gets either eliminated by a suitable {\f3 add()} operation or served by the server thread 
[{\field{\*\fldinst{\lang1024 REF BIB_calciu_adaptive_2014 \\* MERGEFORMAT }}{\fldrslt{calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014}}}
].\par
\pard\plain\s4\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb120 \fi0 2.1  Elimination and Combining\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb60 \fi0 Elimination allows operations to cancel each other out without accessing the shared datastructure. This reduces contention on the priority queue itself and therefore increases parallelism and scalability. The priority queue allows {\f3 removeMin()} operations to eliminate {\f3 add()} operations with keys smaller than {\f3 minValue} and vice versa. An array with a fixed size is used to store data the operations need to exchange 
[{\field{\*\fldinst{\lang1024 REF BIB_calciu_adaptive_2014 \\* MERGEFORMAT }}{\fldrslt{calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014}}}
].\par
\pard\plain\s5\ql\sb240\sa120\keepn\f0\b\fs24\sl240\slmult1 \sb120 \fi0 {\*\bkmkstart BMsec_eliminationArray}2.1.1{\*\bkmkend BMsec_eliminationArray}  Elimination Array\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb60 \fi0 64 bit array slots are used to store a 32-bit value or one of the predefined opcodes as well as a unique stamp for every operation. Valid opcodes are: {\f3 EMPTY}, {\f3 REMREQ}, {\f3 INPROG}, and {\f3 TAKEN}. The values corresponding to these opcodes are not allowed to be used as values in the priority queue. These opcodes have following meaning:\par
{\pard\plain\s46\ql\fi-283\li283\lin283\sb0\sa120\widctlpar\tql\tx283\f0\fs20\sl240\slmult1 \sb50 \li600\fi-300 {\b EMPTY} signals an unused slot of the elimination array. \par
\pard\plain\s46\ql\fi-283\li283\lin283\sb0\sa120\widctlpar\tql\tx283\f0\fs20\sl240\slmult1 \sb50 \li600\fi-300 {\b REMREQ} is used by threads during a {\f3 removeMin()} operation to signal other threads the possibility to eliminate or instruct the server thread to remove an item from the priority queue. \par
\pard\plain\s46\ql\fi-283\li283\lin283\sb0\sa120\widctlpar\tql\tx283\f0\fs20\sl240\slmult1 \sb50 \li600\fi-300 {\b INPROG} signals an adding thread that the server thread started to process the value that it wanted to add. \par
\pard\plain\s46\ql\fi-283\li283\lin283\sb0\sa120\widctlpar\tql\tx283\f0\fs20\sl240\slmult1 \sb50 \li600\fi-300 {\b TAKEN} signals an adding thread that the value has been processed either by the server thread or a removing thread. \par
}\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb60 \fi300 Other values stored in the elimination array are actual values being exchanged. The unique stamp also stored with the opcode/value is used for recognizing changes to the values stored in the elimination array and therefore ensuring linearizablity which will be covered in detail in section\~{\field{\*\fldinst{\lang1024 REF BMsec_linearizablity \\* MERGEFORMAT }}{\fldrslt{3}}}. This stamp is obtained by the thread ID and a thread-local operation counter 
[{\field{\*\fldinst{\lang1024 REF BIB_calciu_adaptive_2014 \\* MERGEFORMAT }}{\fldrslt{calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014}}}
].\par
\pard\plain\s5\ql\sb240\sa120\keepn\f0\b\fs24\sl240\slmult1 \sb120 \fi0 2.1.2  Operations and Elimination\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb60 \fi0 State transitions in the elimination array follow the state machine shown in figure\~{\field{\*\fldinst{\lang1024 REF BMfig_combining_state \\* MERGEFORMAT }}{\fldrslt{2}}}. Every slot is initially {\f3 EMPTY} with a stamp of 0. \par
{\pard\plain\s31\qc\sb120\sa0\keep\widctlpar\f0\fs20\sl240\slmult1 \sb300 \fi0 \par
\pard\plain\s30\ql\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \fi0 {Figure {\*\bkmkstart BMfig_combining_state}2{\*\bkmkend BMfig_combining_state}: Elimination array state transitions 
[{\field{\*\fldinst{\lang1024 REF BIB_calciu_adaptive_2014 \\* MERGEFORMAT }}{\fldrslt{calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014}}}
].}{\field{\*\fldinst TC "2 Elimination array state transitions 
[{\field{\*\fldinst{\lang1024 REF BIB_calciu_adaptive_2014 \\* MERGEFORMAT }}{\fldrslt{calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014}}}
]." \\f f}{\fldrslt }}\par
}\pard\plain\s6\ql\sb240\sa120\keepn\f0\b\fs24\sl240\slmult1 \sb360 \fi0 Add()\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb60 \fi0 A thread trying to add a {\f3 key} (where {{\f3 {\i k}{\i e}{\i y}}<{\f3 {\i m}{\i i}{\i n}{\i V}{\i a}{\i l}{\i u}{\i e}}}) iterates through all slots of the elimination array to find a {\f3 REMREQ} opcode. If it finds one and additionally {{\f3 {\i k}{\i e}{\i y}}<{\f3 {\i m}{\i i}{\i n}{\i V}{\i a}{\i l}{\i u}{\i e}}}, the tread uses {\f3 CAS} to write its value including a stamp into this slot. If multiple attempts fail, the thread instead writes its value into a slot marked as {\f3 EMPTY} and waits for another or the server thread to use the value and change the opcode to {\f3 TAKEN}. The code for this operation can be found in the appendix in algorithm\~{\field{\*\fldinst{\lang1024 REF BMalg_add \\* MERGEFORMAT }}{\fldrslt{1}}} 
[{\field{\*\fldinst{\lang1024 REF BIB_calciu_adaptive_2014 \\* MERGEFORMAT }}{\fldrslt{calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014}}}
].\par
\pard\plain\s6\ql\sb240\sa120\keepn\f0\b\fs24\sl240\slmult1 \sb120 \fi0 RemoveMin()\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb60 \fi0 A thread removing an element from the priority queue iterates through the elimination array until it finds a value or an {\f3 EMPTY} slot in the elimination array. If the stamp of this value is greater than zero, it is checked whether the value is smaller than {\f3 minValue}, otherwise a non positive stamp indicates a value to respond to another {\f3 REMREQ}. In the case of the value being a current minimum of the priority queue the thread uses {\f3 CAS} to replace the value with {\f3 TAKEN}. In the case of finding an empty slot first, a {\f3 REMREQ} with a unique stamp is posted to this slot. Then the thread waits for another thread to eliminate this remove request or the server thread to actually remove one element from the priority queue and post it to this slot of the elimination array. The code for this operation can be found in the appendix in algorithm\~{\field{\*\fldinst{\lang1024 REF BMalg_removeMin \\* MERGEFORMAT }}{\fldrslt{2}}} 
[{\field{\*\fldinst{\lang1024 REF BIB_calciu_adaptive_2014 \\* MERGEFORMAT }}{\fldrslt{calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014}}}
].\par
\pard\plain\s6\ql\sb240\sa120\keepn\f0\b\fs24\sl240\slmult1 \sb120 \fi0 Server Thread\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb60 \fi0 The dedicated server thread is implemented to ensure progress of all threads as not all remove requests and add operations eliminate. The server thread collects all add and remove requests and executes them sequentially on the sequential part of the skiplist. To keep the implementation linearizable the server thread first swaps the value or remove request with {\f3 INPROG}. After the insertion {\f3 TAKEN} is written to the according slot, for removes the value with stamp 0 is written to the slot. The code for this operation can be found in the appendix in algorithm\~{\field{\*\fldinst{\lang1024 REF BMalg_Execute \\* MERGEFORMAT }}{\fldrslt{3}}} 
[{\field{\*\fldinst{\lang1024 REF BIB_calciu_adaptive_2014 \\* MERGEFORMAT }}{\fldrslt{calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014}}}
].\par
\pard\plain\s4\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb120 \fi0 2.2  Skiplist Operations\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb60 \fi0 The priority queue operations {\f3 add()} and {\f3 removeMin()} use the operations described in this section to manipulate the skiplist.\par
\pard\plain\s5\ql\sb240\sa120\keepn\f0\b\fs24\sl240\slmult1 \sb120 \fi0 2.2.1  Sequential Part\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb60 \fi0 The {\f3 addSeq()} and {\f3 removeSeq()} operations are just straight forward skiplist operations as they do not have to deals with any synchronization mechanism. The code for {\f3 removeSeq()} is shown in algorithm\~{\field{\*\fldinst{\lang1024 REF BMalg_RemoveSeq \\* MERGEFORMAT }}{\fldrslt{4}}} 
[{\field{\*\fldinst{\lang1024 REF BIB_calciu_adaptive_2014 \\* MERGEFORMAT }}{\fldrslt{calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014}}}
].\par
\pard\plain\s5\ql\sb240\sa120\keepn\f0\b\fs24\sl240\slmult1 \sb120 \fi0 2.2.2  Parallel Part addPar()\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb60 \fi0 The {\f3 addPar()} operation relies on a Single-Writer-Multi-Reader lock to not manipulate any pointers while head-moving operations are running. To keep the critical section as short as possible this operation first performs a {\f3 cleanFind()} as seen in algorithm\~{\field{\*\fldinst{\lang1024 REF BMalg_CleanFind \\* MERGEFORMAT }}{\fldrslt{5}}}. It searches for the position to insert the element, then acquires the read lock, and checks a timestamp variable manipulated through locking. If the checked timestamp changed between the successful {\f3 find()} and the check within the critical section the operation has to retry from the start. The code is shown in algorithm\~{\field{\*\fldinst{\lang1024 REF BMalg_AddPar \\* MERGEFORMAT }}{\fldrslt{6}}} 
[{\field{\*\fldinst{\lang1024 REF BIB_calciu_adaptive_2014 \\* MERGEFORMAT }}{\fldrslt{calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014}}}
].\par
\pard\plain\s5\ql\sb240\sa120\keepn\f0\b\fs24\sl240\slmult1 \sb120 \fi0 2.2.3  Head-Moving Operations\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb60 \fi0 The head-moving operations are responsible for moving the boundary between the sequential and the parallel part of the skiplist. At the beginning of such a operation a write-lock is acquired to keep other threads from adding elements in parallel while the boundary is manipulated.\par
\pard\plain\s6\ql\sb240\sa120\keepn\f0\b\fs24\sl240\slmult1 \sb120 \fi0 MoveHead()\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb60 \fi0 The {\f3 moveHead()} operation is used to extract a new sequential part from the skiplist if a remove request cannot be served because of an empty sequential part. At first the algorithm decides on how many elements should be moved to the sequential part. The number changes adaptive between {{\field{\*\fldinst{ EQ 2\\s\\up5({\fs16 3})}}{\fldrslt }}
} and {{\field{\*\fldinst{ EQ 2\\s\\up5({\fs16 16})}}{\fldrslt }}
}. If more than {{\i N}} insertions were performed in the sequential part since the last {\f3 moveHead()} was performed, the number of elements to move is doubled, if less than {{\i M}} are inserted then the number is halved. The code is shown in algorithm\~{\field{\*\fldinst{\lang1024 REF BMalg_MoveHead \\* MERGEFORMAT }}{\fldrslt{7}}} 
[{\field{\*\fldinst{\lang1024 REF BIB_calciu_adaptive_2014 \\* MERGEFORMAT }}{\fldrslt{calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014}}}
].\par
\pard\plain\s6\ql\sb240\sa120\keepn\f0\b\fs24\sl240\slmult1 \sb120 \fi0 ChopHead()\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb60 \fi0 The {\f3 chopHead()} operation is called if no remove operations have been performed in a while. This operation relinks the sequential and the parallel part to form a fully parallel skiplist. The code is shown in algorithm\~{\field{\*\fldinst{\lang1024 REF BMalg_ChopHead \\* MERGEFORMAT }}{\fldrslt{8}}} 
[{\field{\*\fldinst{\lang1024 REF BIB_calciu_adaptive_2014 \\* MERGEFORMAT }}{\fldrslt{calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014}}}
].\par
\pard\plain\s4\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb120 \fi0 2.3  Hardware Transactions\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb60 \fi0 {calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014} implemented an alternative design based on hardware transactions to simplify the implementation and get rid of the Single-Writer-Multi-Reader lock. The naive approach of putting all the operations into transactions results into too many retries.  To reduce the number of retries they introduced a timestamp which is increased everytime a head-moving operations starts or finishes. A {\f3 addPar()} operation reads this timestamp and executes a {\f3 find()} before starting a transaction. Within this transaction the actual insertion takes place. The timestamp is added to the transactions read set, which aborts the transaction if the value for the timestamp changes after the transaction started. An unchanged timestamp indicates that the {\f3 find()} operation found valid predecessors and successors for the element to insert, so the transaction can be committed 
[{\field{\*\fldinst{\lang1024 REF BIB_calciu_adaptive_2014 \\* MERGEFORMAT }}{\fldrslt{calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014}}}
]. \par
\column
\pard\plain\s3\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb240 \fi0 {\*\bkmkstart BMsec_linearizablity}3{\*\bkmkend BMsec_linearizablity}  Linearizablity\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb60 \fi0 Linearizability as defined by {herlihy\\s\\do5({\fs16 l})inearizability:\\s\\do5({\fs16 1})990} is a widely used correctness condition for concurrent objects. Linearizability guarantees that each operation appears to have an atomic effect at some point between its invocation and response. This point is typically referred to as linearization point. Combinations of linearizable operations are still linearizable which leads to the definition of linearizable object. Objects are linearizable if each sequence of operations on this objects is linearizable 
[{\field{\*\fldinst{\lang1024 REF BIB_herlihy_linearizability__1990 \\* MERGEFORMAT }}{\fldrslt{herlihy\\s\\do5({\fs16 l})inearizability\\s\\do5({\fs16 \\s\\do4({\fs13 })})1990}}}
].\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \fi300 For the priority queue to meet the desirable linearizability condition it remains to show that each operation is linearizable. \par
\pard\plain\s4\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb120 \fi0 3.1  Skiplist Operations\par
\pard\plain\s6\ql\sb240\sa120\keepn\f0\b\fs24\sl240\slmult1 \sb180 \fi0 AddPar() and AddSeq()\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb60 \fi0 both have their linearization point at the moment the element is added to the bottom level of the skiplist. The only exception is the insertion of a value that is smaller than {\f3 minValue}. In this case the {\f3 minValue} has to be updated. If there is a sequential part, this is done by the server thread, otherwise the performing thread retries until it succeeds or another thread updates it to an even smaller value 
[{\field{\*\fldinst{\lang1024 REF BIB_calciu_adaptive_2014 \\* MERGEFORMAT }}{\fldrslt{calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014}}}
].\par
\pard\plain\s6\ql\sb240\sa120\keepn\f0\b\fs24\sl240\slmult1 \sb120 \fi0 MoveHead() and ChopHead()\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb60 \fi0 both execute while holding the write lock, which means they execute without any thread interfering as no {\f3 addPar()} operation is allowed to run and the other sequential operations are only invoked by the server thread itself 
[{\field{\*\fldinst{\lang1024 REF BIB_calciu_adaptive_2014 \\* MERGEFORMAT }}{\fldrslt{calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014}}}
].\par
\pard\plain\s4\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb120 \fi0 3.2  Elimination and Combining\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb60 \fi0 The unique stamps introduced in section\~{\field{\*\fldinst{\lang1024 REF BMsec_eliminationArray \\* MERGEFORMAT }}{\fldrslt{2.1.1}}} are necessary to avoid the ABA{\cs62\super\chftn}
{\*\footnote\pard \s65\ql\fi-113\li397\lin397\f0\fs20{\cs62\super\chftn} {ABA is not an acronym and is a shortcut for stating that a value at a shared location can change from A to B and then back to A} 
[{\field{\*\fldinst{\lang1024 REF BIB_dechev_understanding_2010 \\* MERGEFORMAT }}{\fldrslt{dechev\\s\\do5({\fs16 u})nderstanding\\s\\do5({\fs16 2})010}}}, 185
].}
 problem. Without this stamp a thread performing an elimination could be interrupted by other threads using the same slot without him noticing it. This would result in an exchange of values with another thread than anticipated, which would break linearizability.\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \fi300 Figure\~{\field{\*\fldinst{\lang1024 REF BMfig_correctness_elim \\* MERGEFORMAT }}{\fldrslt{3}}} visualizes at which point in time two threads involved in an elimination linearize. A thread either inserting or removing a value has to check the exchanged value for being smaller than {\f3 minValue}. In that case the linearization point is at the time of this observation. Other interleaving operations could manipulate the {\f3 minValue} after this observation without breaking linearizability.\par
{\pard\plain\s31\qc\sb120\sa0\keep\widctlpar\f0\fs20\sl240\slmult1 \sb300 \fi0 \par
\pard\plain\s30\ql\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \fi0 {Figure {\*\bkmkstart BMfig_correctness_elim}3{\*\bkmkend BMfig_correctness_elim}: Execution of an {\i op} thread and an {\i inv} thread eliminating each others operation. The linearization point is determined through the observation of the exchanged value being smaller than {\f3 minValue}. It is marked with a red X 
[{\field{\*\fldinst{\lang1024 REF BIB_calciu_adaptive_2014 \\* MERGEFORMAT }}{\fldrslt{calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014}}}
].}{\field{\*\fldinst TC "3 Execution of an {\i op} thread and an {\i inv} thread eliminating each others operation. The linearization point is determined through the observation of the exchanged value being smaller than {\f3 minValue}. It is marked with a red X 
[{\field{\*\fldinst{\lang1024 REF BIB_calciu_adaptive_2014 \\* MERGEFORMAT }}{\fldrslt{calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014}}}
]." \\f f}{\fldrslt }}\par
}\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb240 \fi300 Figure\~{\field{\*\fldinst{\lang1024 REF BMfig_correctness_server \\* MERGEFORMAT }}{\fldrslt{4}}} shows the point in time a thread linearizes while exchanging values with the server thread. The linearizability follows from the linearizability of the skiplist itself and the sequential execution on the skiplist 
[{\field{\*\fldinst{\lang1024 REF BIB_calciu_adaptive_2014 \\* MERGEFORMAT }}{\fldrslt{calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014}}}
]. \par
{\pard\plain\s31\qc\sb120\sa0\keep\widctlpar\f0\fs20\sl240\slmult1 \sb300 \fi0 \par
\pard\plain\s30\ql\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \fi0 {Figure {\*\bkmkstart BMfig_correctness_server}4{\*\bkmkend BMfig_correctness_server}: Execution of an {\i op} having its operation served by the server thread. The linearization point is determined through the sequential operating server thread and is marked with a red X 
[{\field{\*\fldinst{\lang1024 REF BIB_calciu_adaptive_2014 \\* MERGEFORMAT }}{\fldrslt{calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014}}}
].}{\field{\*\fldinst TC "4 Execution of an {\i op} having its operation served by the server thread. The linearization point is determined through the sequential operating server thread and is marked with a red X 
[{\field{\*\fldinst{\lang1024 REF BIB_calciu_adaptive_2014 \\* MERGEFORMAT }}{\fldrslt{calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014}}}
]." \\f f}{\fldrslt }}\par
}\pard\plain\s4\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb360 \fi0 3.3  Hardware Transactions\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb60 \fi0 When using transactions the linearization points are straight forward to determine. Each operation linearizes when the transaction completes successfully. \par
\pard\plain\s3\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb240 \fi0 4  Evaluation\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb60 \fi0 This section describes the result of the empiric evaluation of both described algorithms as well as a comparison with a newer algorithm by {braginsky\\s\\do5({\fs16 c})bpq:\\s\\do5({\fs16 2})016}.\par
\pard\plain\s4\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb120 \fi0 4.1  Single-Writer-Multi-Reader Lock Implementation\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb60 \fi0 For conducting the experiments a Sun SPARC T5240 was used, which consists of two UltraSPARC T2 Plus chips with 8 cores each, running at 1.165\~GHz. Each core provides 8 hardware threads, for a total of 128 threads (64 per chip). Each run was repeated 5 times. The median was used in the charts. Unfortunately the variance was not quantified in the paper. The throughput was measured in a timespan of 10 seconds. To get stable results the priority queue was seeded with 2000 initial elements. The decision whether to perform an {\f3 add()}-operation or an {\f3 removeMin()}-operation was done randomly with a probability of {{\i p}} resulting in one operation and {1\u8722?{\i p}} in the other operation.  The implementation ({\i pqe}) was compared with 4 other priority queue implementations: {\par
\column
\pard\plain\s46\ql\fi-283\li283\lin283\sb0\sa120\widctlpar\tql\tx283\f0\fs20\sl240\slmult1 \sb50 \li600\fi-300 \bullet\tab
The flat combining skiplist ({\i fcskiplist}) and the flat combining pairing heap ({\i fcpairheap}) implementation are both based on the work of {hendler\\s\\do5({\fs16 f})lat\\s\\do5({\fs16 2})010} and use coarse grained locking on a sequential datastructure with flat combining to implement a priority queue algorithm 
[{\field{\*\fldinst{\lang1024 REF BIB_hendler_flat_2010 \\* MERGEFORMAT }}{\fldrslt{hendler\\s\\do5({\fs16 f})lat\\s\\do5({\fs16 2})010}}}
]. \par
\pard\plain\s46\ql\fi-283\li283\lin283\sb0\sa120\widctlpar\tql\tx283\f0\fs20\sl240\slmult1 \sb50 \li600\fi-300 \bullet\tab
The lock free skiplist ({\i lfskiplist}) by {sundell\\s\\do5({\fs16 f})ast\\s\\do5({\fs16 2})003} is based on a parallel skiplist and uses no atomic operations to achieve its lock-freeness. 
[{\field{\*\fldinst{\lang1024 REF BIB_sundell_fast_2003 \\* MERGEFORMAT }}{\fldrslt{sundell\\s\\do5({\fs16 f})ast\\s\\do5({\fs16 2})003}}}
]. \par
\pard\plain\s46\ql\fi-283\li283\lin283\sb0\sa120\widctlpar\tql\tx283\f0\fs20\sl240\slmult1 \sb50 \li600\fi-300 \bullet\tab
The Lazy skiplist ({\i lazyskiplist}) by {lotan\\s\\do5({\fs16 s})kiplist-based\\s\\do5({\fs16 2})000} is based on a parallel skiplist which uses a min-pointer and delete-flags to mark items as taken 
[{\field{\*\fldinst{\lang1024 REF BIB_lotan_skiplist_based_2000 \\* MERGEFORMAT }}{\fldrslt{lotan\\s\\do5({\fs16 s})kiplist\\s\\do5({\fs16 b})ased\\s\\do5({\fs16 2})000}}}
]. \par
}\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb60 \fi300 The evaluation used different scenarios for evaluating the algorithms by varying the proportion of {\f3 add()} operations and {\f3 removeMin()} operations conversely. In figure\~{\field{\*\fldinst{\lang1024 REF BMfig_sparc_50 \\* MERGEFORMAT }}{\fldrslt{5}}} the results for 50\~% {\f3 add()} and 50\~% {\f3 removeMin()} are shown. The use of elimination suggests a good performance in this scenario. As seen in the diagram, the algorithm {\i pqe} indeed performs very well. There is a steady increase in throughput up to the maximum thread-count ({60}) tested, but as the throughput seems to level out around 60 threads it can be assumed that the maximum throughput is reached around this number of threads, especially as the machine had to use the second processor for more than 64 threads. The other algorithms reach their peek-throughput between 4 and 8 threads. For low number of threads ({{\u8804*}8}) the algorithms is significantly outperformed by {\i fcpairheap} because of the overhead for elimination and combining in {\i pqe}.\par
{\pard\plain\s31\qc\sb120\sa0\keep\widctlpar\f0\fs20\sl240\slmult1 \sb300 \fi0 \par
\pard\plain\s30\ql\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \fi0 {Figure {\*\bkmkstart BMfig_sparc_50}5{\*\bkmkend BMfig_sparc_50}: Priority queue performance with 50% {\f3 add()}s, 50% {\f3 removeMin()}s 
[{\field{\*\fldinst{\lang1024 REF BIB_calciu_adaptive_2014 \\* MERGEFORMAT }}{\fldrslt{calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014}}}
].}{\field{\*\fldinst TC "5 Priority queue performance with 50% {\f3 add()}s, 50% {\f3 removeMin()}s 
[{\field{\*\fldinst{\lang1024 REF BIB_calciu_adaptive_2014 \\* MERGEFORMAT }}{\fldrslt{calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014}}}
]." \\f f}{\fldrslt }}\par
}\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb240 \fi300 Figure\~{\field{\*\fldinst{\lang1024 REF BMfig_sparc_80 \\* MERGEFORMAT }}{\fldrslt{6}}} shows the results for 80\~% {\f3 add()} and 20\~% {\f3 removeMin()}. The use of parallel {\f3 add()} operations still suggests a good performance in this scenario although elimination can\rquote t be used that often. Up until 8 threads the {\i pqe} scales very well with a steady increase in throughput, but from 16 threads on the throughput drops again. The {\i lazyskiplist} has a similar performance curve, with lower throughput for {{\u8804*}16} threads but a similar decrease from 16 threads on. The curve of {\i fcpairheap} with a almost static throughput over all tested threadcounts suggests a higher performance than {\i pqe} and {\i lazyskiplist} for higher threadcounts than the ones tested. The throughput of about zero for {\i fcskiplist} seems odd.\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \fi300 The results of the third scenario were not published in the paper by {calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014} but the sourcecode located on the {calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014-1}{journaltitle} website contained the results shown in figure\~{\field{\*\fldinst{\lang1024 REF BMfig_sparc_20 \\* MERGEFORMAT }}{\fldrslt{7}}}. The design of the priority queue with sequential {\f3 removeMin()} operations suggests no good performance in this scenario. As seen in the diagram the {\i pqe} scales quite good with increasing threadcount but has very little throughput in comparison with the other implementations. Other implementations show increasing throughput up to 8 threads, or 16 for {\i fcpairheap}, but decrease in throughput for higher threadcounts. Running with {{\u8804*}8} threads {\i pqe} shows the worst performance of the compared priority queue implementations. {\i Fcpairheap} outperforms {\i pqe} by 50\~% to 400\~%. The reason for increasing throughput between 32 and 48 threads is very unexpected and would need further investigation 
[{\field{\*\fldinst{\lang1024 REF BIB_calciu_adaptive_2014_1 \\* MERGEFORMAT }}{\fldrslt{calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014\\s\\do5({\fs16 1})}}}
].\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \fi300 In conclusion the {\i pqe} implementation performs well in scenarios with balanced operation-proportion and in scenarios with more {\f3 add()} operations but has significant performance issues in scenarios with a high {\f3 removeMin()} operation-proportion. This evaluation shows that the implementation by {calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014} is no general purpose parallel priority queue and developers still have to evaluate their usecase to find the highest performing priority queue implementation.\par
\pard\plain\s5\ql\sb240\sa120\keepn\f0\b\fs24\sl240\slmult1 \sb120 \fi0 4.1.1  Operation Analysis\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb60 \fi0 Figure\~{\field{\*\fldinst{\lang1024 REF BMfig_sparc_add \\* MERGEFORMAT }}{\fldrslt{8}}} shows a diagram breaking down the {\f3 add()} operations optimizations in the different scenarios. While in the first scenario with 80\~% {\f3 add()} operations, parallel {\f3 add()} operations account for more than 75\~% of all the {\f3 add()} operations, while they only account for about 5\~% in the balanced scenario and none in the third scenario. Operations executed by the server play only a little role as the account for less than 5\~% in the first and second scenario and none in the third. The remaining fraction is executed via elimination.\par
{\pard\plain\s31\qc\sb120\sa0\keep\widctlpar\f0\fs20\sl240\slmult1 \sb300 \fi0 \par
\pard\plain\s30\ql\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \fi0 {Figure {\*\bkmkstart BMfig_sparc_add}6{\*\bkmkend BMfig_sparc_add}: {\f3 add()} work breakdown 
[{\field{\*\fldinst{\lang1024 REF BIB_calciu_adaptive_2014 \\* MERGEFORMAT }}{\fldrslt{calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014}}}
].}{\field{\*\fldinst TC "6 {\f3 add()} work breakdown 
[{\field{\*\fldinst{\lang1024 REF BIB_calciu_adaptive_2014 \\* MERGEFORMAT }}{\fldrslt{calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014}}}
]." \\f f}{\fldrslt }}\par
}\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb240 \fi300 The {\f3 removeMin()} operations optimizations are shown in figure\~{\field{\*\fldinst{\lang1024 REF BMfig_sparc_rem \\* MERGEFORMAT }}{\fldrslt{9}}}. In the first scenario with 20\~% {\f3 removeMin()} operations elimination accounts for about 75\~% of all the operations executions. In the balanced scenario elimination accounts for about 90\~% of all the executions while in the last case it is only about 25\~%, which explains the low throughput in this scenario, as 75\~% of all the {\f3 removeMin()} operations, which make up 60\~% of all the operations executed, are executed via the server thread.\par
\pard\plain\s4\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb120 \fi0 4.2  Hardware Transactional Memory Implementation\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb60 \fi0 To evaluate the performance of the hardware transactional memory implementation a Intel Core i7-4770 based computer was used. The four cores run at 3.4\~GHz and provide two hardware threads each. The processor had hardware transactions enabled using restricted transactional memory (RTM) and used all 8 possible hardware threads with hyperthreading enabled. Hyperthreading can influence the performance negatively because of the chache being shared between the 2 running hyperthreads on a core. The application was compiled using the GCC\~4.8 compiler with support for RTM and optimizations enabled (-O3).\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \fi300 Figure\~{\field{\*\fldinst{\lang1024 REF BMfig_tsx1 \\* MERGEFORMAT }}{\fldrslt{10}}} shows the evaluation results in a scenario with 80\~% {\f3 add()} and 20%{\f3 removeMin()} operations for the lock-based implementation ({\i pqe}) and the hardware-transaction based implementation ({\i pqe-tsx}). As seen in the diagram the transaction base implementation starts off with the same throughput for {1+1} threads. The throughput-increase is higher than that for {\i que} resulting in a 20% higher throughput for {1+2} threads and a 40% higher throughput for {1+7} threads.\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \fi300 The second scenario tested with equally many {\f3 add()} and {\f3 removeMin()} operations is shown in figure\~{\field{\*\fldinst{\lang1024 REF BMfig_tsx2 \\* MERGEFORMAT }}{\fldrslt{11}}}. The results obtained in the experiments show almost no difference between the throuput of both implementations. This difference to the other scenario can be explained with the work breakdown shown in figure\~{\field{\*\fldinst{\lang1024 REF BMfig_sparc_add \\* MERGEFORMAT }}{\fldrslt{8}}}. The use of hardware transactional memory speeds up the parallel {\f3 add()} operations, not affecting the performance of other operations in the priority queue. As the first scenario uses about 75% parallel {\f3 add()} operations (60% of all operations) and the second uses only about 5% (2.5% of all operations), the throughput is hardly affected. {\par
\pard\plain\s31\qc\sb120\sa0\keep\widctlpar\f0\fs20\sl240\slmult1 \sb300 \fi0 \par
\pard\plain\s30\ql\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \fi0 {Figure {\*\bkmkstart BMfig_tsx1}7{\*\bkmkend BMfig_tsx1}: Priority queue performance using a transaction-based dual skiplist with 80% {\f3 add()} and 20% {\f3 removeMin()} operations 
[{\field{\*\fldinst{\lang1024 REF BIB_calciu_adaptive_2014 \\* MERGEFORMAT }}{\fldrslt{calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014}}}
].}{\field{\*\fldinst TC "7 Priority queue performance using a transaction-based dual skiplist with 80% {\f3 add()} and 20% {\f3 removeMin()} operations 
[{\field{\*\fldinst{\lang1024 REF BIB_calciu_adaptive_2014 \\* MERGEFORMAT }}{\fldrslt{calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014}}}
]." \\f f}{\fldrslt }}\par
}\pard\plain\s4\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb360 \fi0 4.3  Comparison with Algorithm by {braginsky\\s\\do5({\fs16 c})bpq:\\s\\do5({\fs16 2})016}\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb60 \fi0 {braginsky\\s\\do5({\fs16 c})bpq:\\s\\do5({\fs16 2})016} claim in their paper that they implemented a high performing, lock free, parallel priority queue. They used the original sourcecode by {calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014} for conducting their experiments. The evaluation environment used differs from the one used by {calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014}, as they used a machine with 4 16-core AMD Opteron (TM) 6272 processors having a total of 64 threads. The algorithms were all written in C++ and compiled with a -O3 optimization level on Ubuntu\~14.04 
[{\field{\*\fldinst{\lang1024 REF BIB_braginsky_cbpq__2016 \\* MERGEFORMAT }}{\fldrslt{braginsky\\s\\do5({\fs16 c})bpq\\s\\do5({\fs16 \\s\\do4({\fs13 })})2016}}}
].\par
\column
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \fi300 Figures\~{\field{\*\fldinst{\lang1024 REF BMfig_cbpq_50 \\* MERGEFORMAT }}{\fldrslt{12}}}, {\field{\*\fldinst{\lang1024 REF BMfig_cbpq_80 \\* MERGEFORMAT }}{\fldrslt{13}}} and {\field{\*\fldinst{\lang1024 REF BMfig_cbpq_20 \\* MERGEFORMAT }}{\fldrslt{14}}} show the throughput of the conducted experiments to compare the {\i CBPQ} algorithm by {braginsky\\s\\do5({\fs16 c})bpq:\\s\\do5({\fs16 2})016} to other high performing concurrent priority queue implementations at the time: {\par
\pard\plain\s46\ql\fi-283\li283\lin283\sb0\sa120\widctlpar\tql\tx283\f0\fs20\sl240\slmult1 \sb50 \li600\fi-300 \bullet\tab
The lock free priority queue ({\i LJPQ}) by {linden\\s\\do5({\fs16 s})kiplist-based\\s\\do5({\fs16 2})013} is based on a skiplist and tries to reduce global memory updates to decrease contention in {\f3 removeMin()} operations 
[{\field{\*\fldinst{\lang1024 REF BIB_linden_skiplist_based_2013 \\* MERGEFORMAT }}{\fldrslt{linden\\s\\do5({\fs16 s})kiplist\\s\\do5({\fs16 b})ased\\s\\do5({\fs16 2})013}}}
]. \par
\pard\plain\s46\ql\fi-283\li283\lin283\sb0\sa120\widctlpar\tql\tx283\f0\fs20\sl240\slmult1 \sb50 \li600\fi-300 \bullet\tab
The lock free mound ({\i Mound LF}) and fine grained locking mound ({\i Mound LB}) by {liu\\s\\do5({\fs16 m})ounds:\\s\\do5({\fs16 2})012} based on the mound datastructure. A mound is a randomized balanced tree of sorted lists that allows concurrent {\f3 insert()} and {\f3 extractMin()} operations 
[{\field{\*\fldinst{\lang1024 REF BIB_liu_mounds__2012 \\* MERGEFORMAT }}{\fldrslt{liu\\s\\do5({\fs16 m})ounds\\s\\do5({\fs16 \\s\\do4({\fs13 })})2012}}}
]. \par
\pard\plain\s46\ql\fi-283\li283\lin283\sb0\sa120\widctlpar\tql\tx283\f0\fs20\sl240\slmult1 \sb50 \li600\fi-300 \bullet\tab
The priority queue ({\i APQ}) this paper is based on by {calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014} 
[{\field{\*\fldinst{\lang1024 REF BIB_calciu_adaptive_2014 \\* MERGEFORMAT }}{\fldrslt{calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014}}}
]. \par
}{\pard\plain\s31\qc\sb120\sa0\keep\widctlpar\f0\fs20\sl240\slmult1 \sb360 \fi0 \par
\pard\plain\s30\ql\sb120\sa120\keep\widctlpar\f0\sl240\slmult1 \fi0 {Figure {\*\bkmkstart BMfig_cbpq_50}8{\*\bkmkend BMfig_cbpq_50}: Priority queue throughput in million instructions per second with 50% {\f3 add()}s, 50% {\f3 removeMin()}s 
[{\field{\*\fldinst{\lang1024 REF BIB_braginsky_cbpq__2016 \\* MERGEFORMAT }}{\fldrslt{braginsky\\s\\do5({\fs16 c})bpq\\s\\do5({\fs16 \\s\\do4({\fs13 })})2016}}}
].}{\field{\*\fldinst TC "8 Priority queue throughput in million instructions per second with 50% {\f3 add()}s, 50% {\f3 removeMin()}s 
[{\field{\*\fldinst{\lang1024 REF BIB_braginsky_cbpq__2016 \\* MERGEFORMAT }}{\fldrslt{braginsky\\s\\do5({\fs16 c})bpq\\s\\do5({\fs16 \\s\\do4({\fs13 })})2016}}}
]." \\f f}{\fldrslt }}\par
}\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb240 \fi300 The scalability of {\i APQ} is much worse on the AMD platform than on the original Sun platform. Figure\~{\field{\*\fldinst{\lang1024 REF BMfig_cbpq_50 \\* MERGEFORMAT }}{\fldrslt{12}}} shows that in the scenario with 50% {\f3 add()} operations the algorithm by {calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014} scales well until 7 threads and drops significantly afterwards while other implementations scale better or at least achieve much higher throughput for the tested theadcounts. It remains to mention a good performance of {\i APQ} for low threadcounts ({{\u8804*}7}) in comparison with the testes lock free priority queues except {\i LJPQ}.\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \fi300 The scenario with 80% {\f3 add()} operations in figure\~{\field{\*\fldinst{\lang1024 REF BMfig_cbpq_80 \\* MERGEFORMAT }}{\fldrslt{13}}} shows a very similar curve than the diagram in figure\~{\field{\*\fldinst{\lang1024 REF BMfig_sparc_80 \\* MERGEFORMAT }}{\fldrslt{6}}}. {\i APQ} is outperformed by every other implementation for {{\u8804*}15} threads in this scenario, only the lock free mound implementation ({\i Mound LF}) drops below {\i APQ} for higher threadcounts.\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \fi300 Figure\~{\field{\*\fldinst{\lang1024 REF BMfig_cbpq_20 \\* MERGEFORMAT }}{\fldrslt{14}}} again shows again a poor performance of APQ in comparison with other implementations. The throughput development over the threadcount is on this platform quite different from the one shown in figure\~{\field{\*\fldinst{\lang1024 REF BMfig_sparc_20 \\* MERGEFORMAT }}{\fldrslt{7}}}. The throughput increases until 5 threads but drops afterwards. It can be seen that on the AMD system there is no mysterious performance increase between 32 and 48 threads, as the throughput drops continuously. \par
\pard\plain\s4\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb120 \fi0 4.4  Evaluation Remarks\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb60 \fi0 While reading the original paper, a few odd things came up. The Sun SPARC T5240 machine used for conducting the experiments was introduced in 2008 while the paper was published in 2014. The Intel CPU they used was current model though. Using such an old machine in spite of obviously having a current machine makes you wonder if it was used because the algorithm shows better results on this old machine. Additionally, the experiment was only conducted for up to 60 threads although the machine supports up to 128 threads. The experiment therefore never utilized the second processor.\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \fi300 It would be interesting to know how the priorities used while adding elements were determined. The programming language and operating system was never mentioned, although the paper by {braginsky\\s\\do5({\fs16 c})bpq:\\s\\do5({\fs16 2})016} suggests the use of C++. A uniform scaling of the different diagrams\rquote  axis would increase readability and would ease the comparison between the different diagrams. Especially the scaling of the x-axis makes it hard to analyze the changes between two succeeding values.\par
\pard\plain\s3\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb240 \fi0 5  Conclusion\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb60 \fi0 This paper summarizes the paper by {calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014}. It enriches the information given by the base paper with an extended evaluation containing results from a succeeding paper by {braginsky\\s\\do5({\fs16 c})bpq:\\s\\do5({\fs16 2})016}, some additional prior papers, an explanation of transactional memory, fine-grained structuring, and some remarks on the evaluation.\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \fi300 The paper by {calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014} describes a linearizable, skiplist-based priority queue. To increase the scalability the authors split the skiplist into a sequential part, allowing batched removals by a server thread, and a parallel part, allowing concurrent insertions. The use of elimination reduces the number of updates to the skiplist, by bypassing the actual data structure for allowed operations.\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \fi300 A second implementation described by {calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014} modifies the algorithm to use hardware transactions instead of a Single-Writer-Multi-Reader lock for synchronizing the head-moving operations and concurrent {\f3 add()} operations.\par
\page
\pard\plain\s3\ql\sb240\sa120\keepn\f0\b\fs32\sl240\slmult1 \sb240 \fi0 {\*\bkmkstart BMalg_add}A{\*\bkmkend BMalg_add}  Algorithm\par
\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \sb60 \fi0 All the following algorithms are taken directly from the long version of the paper by {calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014-1} 
[{\field{\*\fldinst{\lang1024 REF BIB_calciu_adaptive_2014_1 \\* MERGEFORMAT }}{\fldrslt{calciu\\s\\do5({\fs16 a})daptive\\s\\do5({\fs16 2})014\\s\\do5({\fs16 1})}}}
].\par
{\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \fi0 \qc [Sorry. Ignored {\plain\f3\\begin\{algorithm\} ... \\end\{algorithm\}}]\par
}{\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \fi0 \qc [Sorry. Ignored {\plain\f3\\begin\{algorithm\} ... \\end\{algorithm\}}]\par
}{\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \fi0 \qc [Sorry. Ignored {\plain\f3\\begin\{algorithm\} ... \\end\{algorithm\}}]\par
}{\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \fi0 \qc [Sorry. Ignored {\plain\f3\\begin\{algorithm\} ... \\end\{algorithm\}}]\par
}{\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \fi0 \qc [Sorry. Ignored {\plain\f3\\begin\{algorithm\} ... \\end\{algorithm\}}]\par
}{\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \fi0 \qc [Sorry. Ignored {\plain\f3\\begin\{algorithm\} ... \\end\{algorithm\}}]\par
}{\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \fi0 \qc [Sorry. Ignored {\plain\f3\\begin\{algorithm\} ... \\end\{algorithm\}}]\par
}{\pard\plain\s0\qj\widctlpar\f0\fs20\sl240\slmult1 \fi0 \qc [Sorry. Ignored {\plain\f3\\begin\{algorithm\} ... \\end\{algorithm\}}]\par
}}}
