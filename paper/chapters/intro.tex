% !TEX root = ../paper.tex

\section{Introduction}

A priority queue is a data structure for storing elements with associated keys. The keys represent priorities. Priority queues can be implemented in two forms: max-priority queues and min-priority queues. The latter one is the form that is considered in this paper.

Typically a min-priority queue exports two operations: \texttt{add()}, for inserting an item into the priority queue, and \texttt{removeMin()} for removing the element with the minimum priority. \citeauthor{cormen_introduction_2009} describe other typical operations of a priority queue like: \texttt{minimum()} for retrieving without removing the minimum-priority-element, and \texttt{decreaseKey()} for decreasing the key of the given element to a given value.

(Parallel) priority queues are often used for resource management in schedulers, for event simulations, or as data structures in graph-algorithms (e.g. Dijkstra's shortest path algorithm, or Prim's minimum spanning tree algorithm) \cite{cormen_introduction_2009}.

\subsection{Prior Work}

The first parallel priority queues implementations were based on heaps and linked lists as it can be seen in the study by \citeauthor{ronngren_comparative_1997} \cite{ronngren_comparative_1997}. Parallel priority queue algorithms based on skiplists were proposed later by \citeauthor{shavit_scalable_1999}. Their implementation deals with bounded range priority queues as found in operating system schedulers. Such queues provide a fixed range of priorities. The algorithm uses coarse-grained locking for synchronizing concurrent \texttt{removeMin()} operations and is based on the concurrent skiplist by \citeauthor{pugh_concurrent_1990} as described in \cite{pugh_concurrent_1990} \cite{shavit_scalable_1999}.

\citeauthor{lotan_skiplist-based_2000} proposed a general purpose priority queue based on \citeauthor{pugh_concurrent_1990}'s concurrent skiplist. Each element has a flag to mark it as deleted. A delete pointer points to the current minimum priority element. Each \texttt{deleteMin()} operation traverses the skiplist until it finds a non marked element. The element is marked and afterwards deleted from the skiplist \cite{lotan_skiplist-based_2000}.

A lock-free priority queue based on a skiplist was introduced by \citeauthor{sundell_fast_2003}. They use different atomic primitive operations like Test-And-Set~(TAS), Fetch-And-Add~(FAA) and Compare-And-Swap~(CAS) to make their priority queue lock-free. For deletion, they use previously unused bits of the pointers in the skiplist to mark the node as deleted \cite{sundell_fast_2003}.

\citeauthor{shavit_elimination_1997} introduced the concept of elimination. This technique allows opposing operations to be coupled together by exchanging data via a small elimination datastructure. The distributed datastructure remains unchanged \cite{shavit_elimination_1997}.

The paper by \citeauthor{hendler_flat_2010} introduced the concept of flat combining. This concept is the opposing strategy to use fine-grained locking to keep the critical region small, as it uses a global lock on the datastructure. All access requests are combined and executed all at once before releasing the lock. The benefit of this approach is the reduced synchronization overhead and the reduced traffic caused by cache invalidations \cite{hendler_flat_2010}.

\subsection{Contributions}

\citeauthor{calciu_adaptive_2014} developed a priority queue based on skiplists. They utilize the skiplists' \enquote{capability for operation-batching and disjoint-access parallelism} \cite[407]{calciu_adaptive_2014}.

The elimination algorithm allows \texttt{add()} operations with keys smaller than the current queue's minimum to eliminate with \texttt{removeMin()} operations. The idea of aging operations also allows \texttt{add()} operations to participate in elimination (if the key is below a certain threshold), even if they are not allowed to eliminate yet.

\texttt{RemoveMin()} operations are combined and delegated to a server thread. This thread is operating on the separate first part of the priority queue and serves every \texttt{removeMin()} and \texttt{add()} operation that is not eliminated.

\texttt{Add()} operations with keys over the threshold mentioned above do not use elimination. They are inserted into the skiplist directly. As inserting elements sequentially would be ineffective the skiplist is split into two parts. The first part is only operated by the server thread. The second part is accessed by all threads in parallel.

This design reduces contention through batched sequential \texttt{removeMin()} and \texttt{add()} (with small keys) operations, by using elimination, and by using parallel \texttt{add()} (with big keys) operations. 

\citeauthor{calciu_adaptive_2014} also implemented the algorithm by using hardware transactional memory instead of locks. The goal of this approach is to further increase performance and to simplify the implementation \cite{calciu_adaptive_2014}.

\subsection{(Hardware) Transactional Memory}

\citeauthor{herlihy_transactional_1993} introduced the concept of transactional memory. Transactional memory allows lock-free implementations of datastructures without having to worry about synchronization. It \enquote{allows programmers to define customized read-modify-write operations that apply to multiple, independently-chosen} sections of memory \cite[289]{herlihy_transactional_1993}.
Such transactional memory can be implemented in software or with the assistance of special hardware instructions \cite{herlihy_transactional_1993}.

Instructions as the Intel Transactional Synchronization Extensions (TSX) \cite{intel_corporation_transactional_2012} build ontop of the concept of transactional memory to provide hardware assisted transactions.
Threads are allowed to execute speculatively in parallel on the shared memory. In case of a conflict only one thread succeeds and all the others have to rollback and retry their operations \cite{calciu_adaptive_2014}.