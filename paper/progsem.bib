
@inproceedings{calciu_adaptive_2014,
	title = {The {Adaptive} {Priority} {Queue} with {Elimination} and {Combining}},
	copyright = {©2014 Springer-Verlag Berlin Heidelberg},
	doi = {10.1007/978-3-662-45174-8_28},
	abstract = {Priority queues are fundamental abstract data structures, often used to manage limited resources in parallel programming. Several proposed parallel priority queue implementations are based on skiplists, harnessing the potential for parallelism of the add() operations. In addition, methods such as Flat Combining have been proposed to reduce contention, batching together multiple operations to be executed by a single thread. While this technique can decrease lock-switching overhead and the number of pointer changes required by the removeMin() operations in the priority queue, it can also create a sequential bottleneck and limit parallelism, especially for non-conflicting add() operations. In this paper, we describe a novel priority queue design, harnessing the scalability of parallel insertions in conjunction with the efficiency of batched removals. Moreover, we present a new elimination algorithm suitable for a priority queue, which further increases concurrency on balanced workloads with similar numbers of add() and removeMin() operations. We implement and evaluate our design using a variety of techniques including locking, atomic operations, hardware transactional memory, as well as employing adaptive heuristics given the workload.},
	booktitle = {Distributed {Computing} ({DISC})},
	author = {Calciu, Irina and Mendes, Hammurabi and Herlihy, Maurice},
	month = oct,
	year = {2014},
	keywords = {Algorithm Analysis and Problem Complexity, Computer Communication Networks, Data Structures, Cryptology and Information Theory},
	pages = {406--420},
	file = {arXiv\:1408.1021 PDF:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\GAC2FXAJ\\Calciu et al. - 2014 - The Adaptive Priority Queue with Elimination and C.pdf:application/pdf;Snapshot:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\8MSN75ID\\978-3-662-45174-8_28.html:text/html}
}

@inproceedings{bar-nissan_dynamic_2011,
	title = {A {Dynamic} {Elimination}-combining {Stack} {Algorithm}},
	doi = {10.1007/978-3-642-25873-2_37},
	abstract = {Two key synchronization paradigms for the construction of scalable concurrent data-structures are software combining and elimination. Elimination-based concurrent data-structures allow operations with reverse semantics (such as push and pop stack operations) to "collide" and exchange values without having to access a central location. Software combining, on the other hand, is effective when colliding operations have identical semantics: when a pair of threads performing operations with identical semantics collide, the task of performing the combined set of operations is delegated to one of the threads and the other thread waits for its operation(s) to be performed. Applying this mechanism iteratively can reduce memory contention and increase throughput. The most highly scalable prior concurrent stack algorithm is the elimination-backoff stack [5]. The elimination-backoff stack provides high parallelism for symmetric workloads in which the numbers of push and pop operations are roughly equal, but its performance deteriorates when workloads are asymmetric. We present DECS, a novel Dynamic Elimination-Combining Stack algorithm, that scales well for all workload types. While maintaining the simplicity and low-overhead of the elimination-bakcoff stack, DECS manages to benefit from collisions of both identical- and reverse-semantics operations. Our empirical evaluation shows that DECS scales significantly better than both blocking and non-blocking best prior stack algorithms.},
	booktitle = {Proceedings of the 15th {International} {Conference} on {Principles} of {Distributed} {Systems} ({OPODIS})},
	author = {Bar-Nissan, Gal and Hendler, Danny and Suissa, Adi},
	year = {2011},
	pages = {544--561},
	file = {arXiv\:1106.6304 PDF:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\WBGD43U4\\Bar-Nissan et al. - 2011 - A Dynamic Elimination-Combining Stack Algorithm.pdf:application/pdf}
}

@inproceedings{hendler_flat_2010,
	title = {Flat {Combining} and the {Synchronization}-parallelism {Tradeoff}},
	doi = {10.1145/1810479.1810540},
	abstract = {Traditional data structure designs, whether lock-based or lock-free, provide parallelism via fine grained synchronization among threads. We introduce a new synchronization paradigm based on coarse locking, which we call flat combining. The cost of synchronization in flat combining is so low, that having a single thread holding a lock perform the combined access requests of all others, delivers, up to a certain non-negligible concurrency level, better performance than the most effective parallel finely synchronized implementations. We use flat-combining to devise, among other structures, new linearizable stack, queue, and priority queue algorithms that greatly outperform all prior algorithms.},
	booktitle = {Proceedings of the {Twenty}-second {Annual} {ACM} {Symposium} on {Parallelism} in {Algorithms} and {Architectures} ({SPAA})},
	author = {Hendler, Danny and Incze, Itai and Shavit, Nir and Tzafrir, Moran},
	year = {2010},
	keywords = {concurrent data-structures, multiprocessors, synchronization},
	pages = {355--364},
	file = {ACM Full Text PDF:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\XUI8P7WT\\Hendler et al. - 2010 - Flat Combining and the Synchronization-parallelism.pdf:application/pdf}
}

@inproceedings{sundell_fast_2003,
	title = {Fast and {Lock}-{Free} {Concurrent} {Priority} {Queues} for {Multi}-{Thread} {Systems}},
	doi = {10.1109/IPDPS.2003.1213189},
	abstract = {We present an efficient and practical lock-free implementation of a concurrent priority queue that is suitable for both fully concurrent (large multi-processor) systems as well as pre-emptive (multi-process) systems. Many algorithms for concurrent priority queues are based on mutual exclusion. However, mutual exclusion causes blocking which has several drawbacks anddegrades the system's overall performance. Non-blocking algorithms avoid blocking, and are either lock-free or wait-free. Previously known non-blocking algorithms of priority queues did not perform well in practice because of their complexity, and they are often based on non-available atomic synchronization primitives. Our algorithm is based on the randomizedsequential list structure called Skiplist, and a real-time extension of our algorithm is also described. In our performance evaluation we compare our algorithm with some of the most efficient implementations of priority queues known. The experimental results clearly show that our lock-free implementation outperforms the other lock-based implementations in all cases for 3 threads and more, both on fully concurrent as well as on pre-emptive systems.},
	booktitle = {Proceedings of the 17th {International} {Symposium} on {Parallel} and {Distributed} {Processing} ({IPDPS})},
	author = {Sundell, Hakan and Tsigas, Philippas},
	year = {2003},
	keywords = {Lock-Free, Multi-Thread, Non-Blocking, Parallel, Priority Queue, Shared Memory},
	pages = {84.2--},
	file = {SunT03_PQueue_TR.pdf:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\ZX66A7VF\\SunT03_PQueue_TR.pdf:application/pdf}
}

@inproceedings{lotan_skiplist-based_2000,
	title = {Skiplist-{Based} {Concurrent} {Priority} {Queues}},
	doi = {10.1109/IPDPS.2000.845994},
	booktitle = {Proceedings of the 14th {International} {Symposium} on {Parallel} and {Distributed} {Processing} ({IPDPS})},
	author = {Lotan, Itay and Shavit, Nir},
	year = {2000},
	pages = {263--268},
	file = {Priority_Queues.pdf:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\G82DM3GJ\\Priority_Queues.pdf:application/pdf}
}

@article{herlihy_linearizability:_1990,
	title = {Linearizability: {A} {Correctness} {Condition} for {Concurrent} {Objects}},
	volume = {12},
	shorttitle = {Linearizability},
	doi = {10.1145/78969.78972},
	abstract = {A concurrent object is a data object shared by concurrent processes. Linearizability is a correctness condition for concurrent objects that exploits the semantics of abstract data types. It permits a high degree of concurrency, yet it permits programmers to specify and reason about concurrent objects using known techniques from the sequential domain. Linearizability provides the illusion that each operation applied by concurrent processes takes effect instantaneously at some point between its invocation and its response, implying that the meaning of a concurrent object's operations can be given by pre- and post-conditions. This paper defines linearizability, compares it to other correctness conditions, presents and demonstrates a method for proving the correctness of implementations, and shows how to reason about concurrent objects, given they are linearizable.},
	number = {3},
	journal = {ACM Transactions on Programming Languages and Systems (TOPLAS)},
	author = {Herlihy, Maurice P. and Wing, Jeannette M.},
	month = jul,
	year = {1990},
	pages = {463--492},
	file = {p463-herlihy.pdf:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\6SPAJP3C\\p463-herlihy.pdf:application/pdf}
}

@book{cormen_introduction_2009,
	address = {Cambridge},
	edition = {3},
	title = {Introduction to algorithms},
	isbn = {978-0-262-03384-8},
	abstract = {Literaturverz. S. [1231] - 1250, Hier auch später erschienene, unveränderte Nachdrucke (2010)},
	publisher = {The MIT Press},
	author = {Cormen, Thomas H. and Leiserson, Charles E. and Rivest, Ronald L. and Stein, Clifford},
	year = {2009},
	keywords = {Algorithmen, Algorithmus ; Datenstruktur ; Lehrbuch, Computer algorithms., Computer programming., (DE-588)4001183-5, (DE-588)4011146-5},
	file = {Introduction.to.Algorithms.3rd.Edition.Sep.2010.pdf:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\ZGHEVX7Q\\Introduction.to.Algorithms.3rd.Edition.Sep.2010.pdf:application/pdf}
}

@article{hunt_efficient_1996,
	title = {An efficient algorithm for concurrent priority queue heaps},
	volume = {60},
	number = {3},
	journal = {Information Processing Letters},
	author = {Hunt, Galen C. and Michael, Maged M. and Parthasarathy, Srinivasan and Scott, Michael L.},
	year = {1996},
	pages = {151--157},
	file = {ipl-1996.pdf:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\UPMMRQPJ\\ipl-1996.pdf:application/pdf}
}

@article{rao_concurrent_1988,
	title = {Concurrent access of priority queues},
	volume = {37},
	doi = {10.1109/12.9744},
	abstract = {Contention for the shared heap limits the obtainable speedup in parallel algorithms using this data structure as a priority queue. An approach that allows concurrent insertions and deletions on the heap in a shared-memory multiprocessor is presented. The scheme retains the strict priority ordering of the serial-access heap algorithms, i.e. a delete operation returns the best key of all keys that have been inserted or are being inserted at the time delete is started. Experimental results on the BBN Butterfly parallel processor demonstrate that the use of concurrent-heap algorithms in parallel branch-and-bound improves its performance substantially},
	number = {12},
	journal = {IEEE Transactions on Computers},
	author = {Rao, V. Nageshwara and Kumar, Vipin},
	month = dec,
	year = {1988},
	keywords = {BBN Butterfly parallel processor, Broadcasting, Clocks, Computer science, Concurrent computing, concurrent-heap algorithms, data structure, Data structures, Fault diagnosis, Hypercubes, multiprocessing systems, parallel algorithms, parallel branch-and-bound, priority queues, Processor scheduling, queueing theory, Real time systems, shared heap, shared-memory multiprocessor},
	pages = {1657--1665},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\MBZGJSPB\\9744.html:text/html;tr88-06.pdf:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\3ZFPPQS5\\tr88-06.pdf:application/pdf}
}

@article{ronngren_comparative_1997,
	title = {A {Comparative} {Study} of {Parallel} and {Sequential} {Priority} {Queue} {Algorithms}},
	volume = {7},
	doi = {10.1145/249204.249205},
	abstract = {Priority queues are used  in many applications including real-time systems, operating systems, and simulations. Their implementation may have a profound effect on the performance of such applications. In this article, we study the performance of well-known sequential priority queue implementations and the recently proposed parallel access priority queues. To accurately assess the performance of a priority queue, the performance measurement methodology must be appropriate. We use the Classic Hold, the Markov Model, and an Up/Down access pattern to measure performance and look at both the average access time and the worst-case time that are of vital interest to real-tiem applicatons. Our results suggest that the best choice for priority queue algorithms depends heavily on the application. For queue sizes smaller than 1,000 elements, the Splay Tree, the Skew Heap, and Henriksen's algorithm show good average access times. For large queue sized of 5,000 elements or more, the Calendar Queue and the Lazy Queue offer good average access times but have very long worst-case access times. The Skew Heap and the splay Tree exhibit the best worst-case access times. Among the parallel access priority queues tested, the Parallel Access Skew Heap provides the best performance on small shares memory multiprocessors.},
	number = {2},
	journal = {ACM Trans. Model. Comput. Simul.},
	author = {Rönngren, Robert and Ayani, Rassul},
	month = apr,
	year = {1997},
	keywords = {parallel access priority queue, pending event set implementations, Priority Queue},
	pages = {157--209},
	file = {10.1.1.4.3753.pdf:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\MF3GKF72\\10.1.1.4.3753.pdf:application/pdf}
}

@inproceedings{shavit_scalable_1999,
	title = {Scalable {Concurrent} {Priority} {Queue} {Algorithms}},
	doi = {10.1145/301308.301339},
	booktitle = {Proceedings of the {Eighteenth} {Annual} {ACM} {Symposium} on {Principles} of {Distributed} {Computing} ({PODC})},
	author = {Shavit, Nir and Zemach, Asaph},
	year = {1999},
	pages = {113--122},
	file = {10.1.1.38.9977.pdf:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\CN9F4N86\\10.1.1.38.9977.pdf:application/pdf}
}

@inproceedings{hendler_scalable_2004,
	title = {A {Scalable} {Lock}-free {Stack} {Algorithm}},
	isbn = {978-1-58113-840-5},
	doi = {10.1145/1007912.1007944},
	abstract = {The literature describes two high performance concurrent stack algorithms based on combining funnels and elimination trees. Unfortunately, the funnels are linearizable but blocking, and the elimination trees are non-blocking but not linearizable. Neither is used in practice since they perform well only at exceptionally high loads. The literature also describes a simple lock-free linearizable stack algorithm that works at low loads but does not scale as the load increases. The question of designing a stack algorithm that is non-blocking, linearizable, and scales well throughout the concurrency range, has thus remained open.This paper presents such a concurrent stack algorithm. It is based on the following simple observation: that a single elimination array used as a backoff scheme for a simple lock-free stack is lock-free, linearizable, and scalable. As our empirical results show, the resulting elimination-backoff stack performs as well as the simple stack at low loads, and increasingly outperforms all other methods (lock-based and non-blocking) as concurrency increases. We believe its simplicity and scalability make it a viable practical alternative to existing constructions for implementing concurrent stacks.},
	booktitle = {Proceedings of the {Sixteenth} {Annual} {ACM} {Symposium} on {Parallelism} in {Algorithms} and {Architectures} ({SPAA})},
	author = {Hendler, Danny and Shavit, Nir and Yerushalmi, Lena},
	year = {2004},
	pages = {206--215},
	file = {p206-hendler.pdf:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\T3SD3AUH\\p206-hendler.pdf:application/pdf}
}

@inproceedings{alistarh_spraylist:_2015,
	title = {The {SprayList}: {A} {Scalable} {Relaxed} {Priority} {Queue}},
	doi = {10.1145/2688500.2688523},
	abstract = {High-performance concurrent priority queues are essential for applications such as task scheduling and discrete event simulation. Unfortunately, even the best performing implementations do not scale past a number of threads in the single digits. This is because of the sequential bottleneck in accessing the elements at the head of the queue in order to perform a DeleteMin operation. In this paper, we present the SprayList, a scalable priority queue with relaxed ordering semantics. Starting from a non-blocking SkipList, the main innovation behind our design is that the DeleteMin operations avoid a sequential bottleneck by ``spraying'' themselves onto the head of the SkipList list in a coordinated fashion. The spraying is implemented using a carefully designed random walk, so that DeleteMin returns an element among the first O(p log{\textasciicircum}3 p) in the list, with high probability, where p is the number of threads. We prove that the running time of a DeleteMin operation is O(log{\textasciicircum}3 p), with high probability, independent of the size of the list. Our experiments show that the relaxed semantics allow the data structure to scale for high thread counts, comparable to a classic unordered SkipList. Furthermore, we observe that, for reasonably parallel workloads, the scalability benefits of relaxation considerably outweigh the additional work due to out-of-order execution.},
	booktitle = {Proceedings of the 20th {ACM} {SIGPLAN} {Symposium} on {Principles} and {Practice} of {Parallel} {Programming} ({PPoPP})},
	author = {Alistarh, Dan and Kopinsky, Justin and Li, Jerry and Shavit, Nir},
	year = {2015},
	keywords = {Concurrent data structures, parallel algorithms},
	pages = {11--20},
	file = {ACM Full Text PDF:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\EIW6CDEV\\Alistarh et al. - 2015 - The SprayList A Scalable Relaxed Priority Queue.pdf:application/pdf}
}

@article{rihani_multiqueues:_2014,
	title = {{MultiQueues}: {Simpler}, {Faster}, and {Better} {Relaxed} {Concurrent} {Priority} {Queues}},
	url = {http://arxiv.org/abs/1411.1209},
	abstract = {Priority queues with parallel access are an attractive data structure for applications like prioritized online scheduling, discrete event simulation, or branch-and-bound. However, a classical priority queue constitutes a severe bottleneck in this context, leading to very small throughput. Hence, there has been significant interest in concurrent priority queues with a somewhat relaxed semantics where deleted elements only need to be close to the minimum. In this paper we present a very simple approach based on multiple sequential priority queues. It turns out to outperform previous more complicated data structures while at the same time improving the quality of the returned elements.},
	author = {Rihani, Hamza and Sanders, Peter and Dementiev, Roman},
	month = nov,
	year = {2014},
	keywords = {Computer Science - Data Structures and Algorithms},
	file = {arXiv\:1411.1209 PDF:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\HNV39ER6\\Rihani et al. - 2014 - MultiQueues Simpler, Faster, and Better Relaxed C.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\8PCPE3SG\\1411.html:text/html}
}

@inproceedings{wimmer_lock-free_2015,
	title = {The {Lock}-free k-{LSM} {Relaxed} {Priority} {Queue}},
	doi = {10.1145/2688500.2688547},
	abstract = {We present a new, concurrent, lock-free priority queue that relaxes the delete-min operation to allow deletion of any of the ρ smallest keys instead of only a minimal one, where ρ is a parameter that can be configured at runtime. It is built from a logarithmic number of sorted arrays, similar to log-structured merge-trees (LSM). For keys added and removed by the same thread the behavior is identical to a non-relaxed priority queue. We compare to state-of-the-art lock-free priority queues with both relaxed and non-relaxed semantics, showing high performance and good scalability of our approach.},
	booktitle = {Proceedings of the 20th {ACM} {SIGPLAN} {Symposium} on {Principles} and {Practice} of {Parallel} {Programming} ({PPoPP})},
	author = {Wimmer, Martin and Gruber, Jakob and Träff, Jesper Larsson and Tsigas, Philippas},
	year = {2015},
	keywords = {concurrent data structure relaxation, priority-queue, Shared Memory, Task-parallel programming},
	pages = {277--278},
	file = {ACM Full Text PDF:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\2XWRDV9K\\Wimmer et al. - 2015 - The Lock-free k-LSM Relaxed Priority Queue.pdf:application/pdf}
}

@inproceedings{braginsky_cbpq:_2016,
	title = {{CBPQ}: {High} {Performance} {Lock}-{Free} {Priority} {Queue}},
	copyright = {©2016 Springer International Publishing Switzerland},
	doi = {10.1007/978-3-319-43659-3_34},
	abstract = {Priority queues are an important algorithmic component and are ubiquitous in systems and software. With the rapid deployment of parallel platforms, concurrent versions of priority queues are becoming increasingly important. In this paper, we present a novel concurrent lock-free linearizable algorithm for priority queues that scales significantly better than all known (lock-based or lock-free) priority queues. Our design employs several techniques to obtain its advantages including lock-free chunks, the use of the efficient fetch-and-increment atomic instruction, and elimination. Measurements under high contention demonstrate performance improvement by up to a factor of 1.8 over existing approaches.},
	booktitle = {European {Conference} on {Parallel} {Processing} 2016: {Parallel} {Processing} ({EUROPAR})},
	author = {Braginsky, Anastasia and Cohen, Nachshon and Petrank, Erez},
	month = aug,
	year = {2016},
	keywords = {Algorithm Analysis and Problem Complexity, Computer System Implementation, Discrete Mathematics in Computer Science, Freezing, Lock-Free, Non-Blocking, Performance, Priority Queue, Programming Languages, Compilers, Interpreters, Programming Techniques, Special Purpose and Application-Based Systems},
	pages = {460--474},
	file = {Full Text PDF:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\HWAUG2RP\\Braginsky et al. - 2016 - CBPQ High Performance Lock-Free Priority Queue.pdf:application/pdf;Snapshot:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\NZJXP2TP\\978-3-319-43659-3_34.html:text/html}
}