
@inproceedings{calciu_adaptive_2014,
	title = {The {Adaptive} {Priority} {Queue} with {Elimination} and {Combining}},
	copyright = {©2014 Springer-Verlag Berlin Heidelberg},
	doi = {10.1007/978-3-662-45174-8_28},
	abstract = {Priority queues are fundamental abstract data structures, often used to manage limited resources in parallel programming. Several proposed parallel priority queue implementations are based on skiplists, harnessing the potential for parallelism of the add() operations. In addition, methods such as Flat Combining have been proposed to reduce contention, batching together multiple operations to be executed by a single thread. While this technique can decrease lock-switching overhead and the number of pointer changes required by the removeMin() operations in the priority queue, it can also create a sequential bottleneck and limit parallelism, especially for non-conflicting add() operations. In this paper, we describe a novel priority queue design, harnessing the scalability of parallel insertions in conjunction with the efficiency of batched removals. Moreover, we present a new elimination algorithm suitable for a priority queue, which further increases concurrency on balanced workloads with similar numbers of add() and removeMin() operations. We implement and evaluate our design using a variety of techniques including locking, atomic operations, hardware transactional memory, as well as employing adaptive heuristics given the workload.},
	booktitle = {Distributed {Computing} ({DISC})},
	author = {Calciu, Irina and Mendes, Hammurabi and Herlihy, Maurice},
	month = oct,
	year = {2014},
	keywords = {Algorithm Analysis and Problem Complexity, Computer Communication Networks, Data Structures, Cryptology and Information Theory},
	pages = {406--420},
	file = {arXiv\:1408.1021 PDF:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\GAC2FXAJ\\Calciu et al. - 2014 - The Adaptive Priority Queue with Elimination and C.pdf:application/pdf;Snapshot:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\8MSN75ID\\978-3-662-45174-8_28.html:text/html}
}

@inproceedings{bar-nissan_dynamic_2011,
	title = {A {Dynamic} {Elimination}-combining {Stack} {Algorithm}},
	doi = {10.1007/978-3-642-25873-2_37},
	abstract = {Two key synchronization paradigms for the construction of scalable concurrent data-structures are software combining and elimination. Elimination-based concurrent data-structures allow operations with reverse semantics (such as push and pop stack operations) to "collide" and exchange values without having to access a central location. Software combining, on the other hand, is effective when colliding operations have identical semantics: when a pair of threads performing operations with identical semantics collide, the task of performing the combined set of operations is delegated to one of the threads and the other thread waits for its operation(s) to be performed. Applying this mechanism iteratively can reduce memory contention and increase throughput. The most highly scalable prior concurrent stack algorithm is the elimination-backoff stack [5]. The elimination-backoff stack provides high parallelism for symmetric workloads in which the numbers of push and pop operations are roughly equal, but its performance deteriorates when workloads are asymmetric. We present DECS, a novel Dynamic Elimination-Combining Stack algorithm, that scales well for all workload types. While maintaining the simplicity and low-overhead of the elimination-bakcoff stack, DECS manages to benefit from collisions of both identical- and reverse-semantics operations. Our empirical evaluation shows that DECS scales significantly better than both blocking and non-blocking best prior stack algorithms.},
	booktitle = {Proceedings of the 15th {International} {Conference} on {Principles} of {Distributed} {Systems} ({OPODIS})},
	author = {Bar-Nissan, Gal and Hendler, Danny and Suissa, Adi},
	year = {2011},
	pages = {544--561},
	file = {arXiv\:1106.6304 PDF:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\WBGD43U4\\Bar-Nissan et al. - 2011 - A Dynamic Elimination-Combining Stack Algorithm.pdf:application/pdf}
}

@inproceedings{hendler_flat_2010,
	title = {Flat {Combining} and the {Synchronization}-parallelism {Tradeoff}},
	doi = {10.1145/1810479.1810540},
	abstract = {Traditional data structure designs, whether lock-based or lock-free, provide parallelism via fine grained synchronization among threads. We introduce a new synchronization paradigm based on coarse locking, which we call flat combining. The cost of synchronization in flat combining is so low, that having a single thread holding a lock perform the combined access requests of all others, delivers, up to a certain non-negligible concurrency level, better performance than the most effective parallel finely synchronized implementations. We use flat-combining to devise, among other structures, new linearizable stack, queue, and priority queue algorithms that greatly outperform all prior algorithms.},
	booktitle = {Proceedings of the {Twenty}-second {Annual} {ACM} {Symposium} on {Parallelism} in {Algorithms} and {Architectures} ({SPAA})},
	author = {Hendler, Danny and Incze, Itai and Shavit, Nir and Tzafrir, Moran},
	year = {2010},
	keywords = {concurrent data-structures, multiprocessors, synchronization},
	pages = {355--364},
	file = {ACM Full Text PDF:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\XUI8P7WT\\Hendler et al. - 2010 - Flat Combining and the Synchronization-parallelism.pdf:application/pdf}
}

@inproceedings{sundell_fast_2003,
	title = {Fast and {Lock}-{Free} {Concurrent} {Priority} {Queues} for {Multi}-{Thread} {Systems}},
	doi = {10.1109/IPDPS.2003.1213189},
	abstract = {We present an efficient and practical lock-free implementation of a concurrent priority queue that is suitable for both fully concurrent (large multi-processor) systems as well as pre-emptive (multi-process) systems. Many algorithms for concurrent priority queues are based on mutual exclusion. However, mutual exclusion causes blocking which has several drawbacks anddegrades the system's overall performance. Non-blocking algorithms avoid blocking, and are either lock-free or wait-free. Previously known non-blocking algorithms of priority queues did not perform well in practice because of their complexity, and they are often based on non-available atomic synchronization primitives. Our algorithm is based on the randomizedsequential list structure called Skiplist, and a real-time extension of our algorithm is also described. In our performance evaluation we compare our algorithm with some of the most efficient implementations of priority queues known. The experimental results clearly show that our lock-free implementation outperforms the other lock-based implementations in all cases for 3 threads and more, both on fully concurrent as well as on pre-emptive systems.},
	booktitle = {Proceedings of the 17th {International} {Symposium} on {Parallel} and {Distributed} {Processing} ({IPDPS})},
	author = {Sundell, Hakan and Tsigas, Philippas},
	year = {2003},
	keywords = {Lock-Free, Multi-Thread, Non-Blocking, Parallel, Priority Queue, Shared Memory},
	pages = {84.2--},
	file = {SunT03_PQueue_TR.pdf:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\ZX66A7VF\\SunT03_PQueue_TR.pdf:application/pdf}
}

@inproceedings{lotan_skiplist-based_2000,
	title = {Skiplist-{Based} {Concurrent} {Priority} {Queues}},
	doi = {10.1109/IPDPS.2000.845994},
	booktitle = {Proceedings of the 14th {International} {Symposium} on {Parallel} and {Distributed} {Processing} ({IPDPS})},
	author = {Lotan, Itay and Shavit, Nir},
	year = {2000},
	pages = {263--268},
	file = {Priority_Queues.pdf:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\G82DM3GJ\\Priority_Queues.pdf:application/pdf}
}

@article{herlihy_linearizability:_1990,
	title = {Linearizability: {A} {Correctness} {Condition} for {Concurrent} {Objects}},
	volume = {12},
	shorttitle = {Linearizability},
	doi = {10.1145/78969.78972},
	abstract = {A concurrent object is a data object shared by concurrent processes. Linearizability is a correctness condition for concurrent objects that exploits the semantics of abstract data types. It permits a high degree of concurrency, yet it permits programmers to specify and reason about concurrent objects using known techniques from the sequential domain. Linearizability provides the illusion that each operation applied by concurrent processes takes effect instantaneously at some point between its invocation and its response, implying that the meaning of a concurrent object's operations can be given by pre- and post-conditions. This paper defines linearizability, compares it to other correctness conditions, presents and demonstrates a method for proving the correctness of implementations, and shows how to reason about concurrent objects, given they are linearizable.},
	number = {3},
	journal = {ACM Transactions on Programming Languages and Systems (TOPLAS)},
	author = {Herlihy, Maurice P. and Wing, Jeannette M.},
	month = jul,
	year = {1990},
	pages = {463--492},
	file = {p463-herlihy.pdf:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\6SPAJP3C\\p463-herlihy.pdf:application/pdf}
}

@inproceedings{braginsky_cbpq:_2016,
	title = {{CBPQ}: {High} {Performance} {Lock}-{Free} {Priority} {Queue}},
	copyright = {©2016 Springer International Publishing Switzerland},
	doi = {10.1007/978-3-319-43659-3_34},
	abstract = {Priority queues are an important algorithmic component and are ubiquitous in systems and software. With the rapid deployment of parallel platforms, concurrent versions of priority queues are becoming increasingly important. In this paper, we present a novel concurrent lock-free linearizable algorithm for priority queues that scales significantly better than all known (lock-based or lock-free) priority queues. Our design employs several techniques to obtain its advantages including lock-free chunks, the use of the efficient fetch-and-increment atomic instruction, and elimination. Measurements under high contention demonstrate performance improvement by up to a factor of 1.8 over existing approaches.},
	booktitle = {European {Conference} on {Parallel} {Processing} 2016: {Parallel} {Processing} ({EUROPAR})},
	author = {Braginsky, Anastasia and Cohen, Nachshon and Petrank, Erez},
	month = aug,
	year = {2016},
	keywords = {Algorithm Analysis and Problem Complexity, Computer System Implementation, Discrete Mathematics in Computer Science, Freezing, Lock-Free, Non-Blocking, Performance, Priority Queue, Programming Languages, Compilers, Interpreters, Programming Techniques, Special Purpose and Application-Based Systems},
	pages = {460--474},
	file = {Full Text PDF:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\HWAUG2RP\\Braginsky et al. - 2016 - CBPQ High Performance Lock-Free Priority Queue.pdf:application/pdf;Snapshot:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\NZJXP2TP\\978-3-319-43659-3_34.html:text/html}
}

@book{cormen_introduction_2009,
	address = {Cambridge},
	edition = {3},
	title = {Introduction to algorithms},
	isbn = {978-0-262-03384-8},
	abstract = {Literaturverz. S. [1231] - 1250, Hier auch später erschienene, unveränderte Nachdrucke (2010)},
	publisher = {The MIT Press},
	author = {Cormen, Thomas H. and Leiserson, Charles E. and Rivest, Ronald L. and Stein, Clifford},
	year = {2009},
	keywords = {Algorithmen, Algorithmus ; Datenstruktur ; Lehrbuch, Computer algorithms., Computer programming., (DE-588)4001183-5, (DE-588)4011146-5},
	file = {Introduction.to.Algorithms.3rd.Edition.Sep.2010.pdf:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\ZGHEVX7Q\\Introduction.to.Algorithms.3rd.Edition.Sep.2010.pdf:application/pdf}
}

@article{hunt_efficient_1996,
	title = {An efficient algorithm for concurrent priority queue heaps},
	volume = {60},
	number = {3},
	journal = {Information Processing Letters},
	author = {Hunt, Galen C. and Michael, Maged M. and Parthasarathy, Srinivasan and Scott, Michael L.},
	year = {1996},
	pages = {151--157},
	file = {ipl-1996.pdf:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\UPMMRQPJ\\ipl-1996.pdf:application/pdf}
}

@article{rao_concurrent_1988,
	title = {Concurrent access of priority queues},
	volume = {37},
	doi = {10.1109/12.9744},
	abstract = {Contention for the shared heap limits the obtainable speedup in parallel algorithms using this data structure as a priority queue. An approach that allows concurrent insertions and deletions on the heap in a shared-memory multiprocessor is presented. The scheme retains the strict priority ordering of the serial-access heap algorithms, i.e. a delete operation returns the best key of all keys that have been inserted or are being inserted at the time delete is started. Experimental results on the BBN Butterfly parallel processor demonstrate that the use of concurrent-heap algorithms in parallel branch-and-bound improves its performance substantially},
	number = {12},
	journal = {IEEE Transactions on Computers},
	author = {Rao, V. Nageshwara and Kumar, Vipin},
	month = dec,
	year = {1988},
	keywords = {BBN Butterfly parallel processor, Broadcasting, Clocks, Computer science, Concurrent computing, concurrent-heap algorithms, data structure, Data structures, Fault diagnosis, Hypercubes, multiprocessing systems, parallel algorithms, parallel branch-and-bound, priority queues, Processor scheduling, queueing theory, Real time systems, shared heap, shared-memory multiprocessor},
	pages = {1657--1665},
	file = {IEEE Xplore Abstract Record:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\MBZGJSPB\\9744.html:text/html;tr88-06.pdf:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\3ZFPPQS5\\tr88-06.pdf:application/pdf}
}

@article{ronngren_comparative_1997,
	title = {A {Comparative} {Study} of {Parallel} and {Sequential} {Priority} {Queue} {Algorithms}},
	volume = {7},
	doi = {10.1145/249204.249205},
	abstract = {Priority queues are used  in many applications including real-time systems, operating systems, and simulations. Their implementation may have a profound effect on the performance of such applications. In this article, we study the performance of well-known sequential priority queue implementations and the recently proposed parallel access priority queues. To accurately assess the performance of a priority queue, the performance measurement methodology must be appropriate. We use the Classic Hold, the Markov Model, and an Up/Down access pattern to measure performance and look at both the average access time and the worst-case time that are of vital interest to real-tiem applicatons. Our results suggest that the best choice for priority queue algorithms depends heavily on the application. For queue sizes smaller than 1,000 elements, the Splay Tree, the Skew Heap, and Henriksen's algorithm show good average access times. For large queue sized of 5,000 elements or more, the Calendar Queue and the Lazy Queue offer good average access times but have very long worst-case access times. The Skew Heap and the splay Tree exhibit the best worst-case access times. Among the parallel access priority queues tested, the Parallel Access Skew Heap provides the best performance on small shares memory multiprocessors.},
	number = {2},
	journal = {ACM Trans. Model. Comput. Simul.},
	author = {Rönngren, Robert and Ayani, Rassul},
	month = apr,
	year = {1997},
	keywords = {parallel access priority queue, pending event set implementations, Priority Queue},
	pages = {157--209},
	file = {10.1.1.4.3753.pdf:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\MF3GKF72\\10.1.1.4.3753.pdf:application/pdf}
}

@inproceedings{shavit_scalable_1999,
	title = {Scalable {Concurrent} {Priority} {Queue} {Algorithms}},
	doi = {10.1145/301308.301339},
	booktitle = {Proceedings of the {Eighteenth} {Annual} {ACM} {Symposium} on {Principles} of {Distributed} {Computing} ({PODC})},
	author = {Shavit, Nir and Zemach, Asaph},
	year = {1999},
	pages = {113--122},
	file = {10.1.1.38.9977.pdf:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\CN9F4N86\\10.1.1.38.9977.pdf:application/pdf}
}

@inproceedings{hendler_scalable_2004,
	title = {A {Scalable} {Lock}-free {Stack} {Algorithm}},
	isbn = {978-1-58113-840-5},
	doi = {10.1145/1007912.1007944},
	abstract = {The literature describes two high performance concurrent stack algorithms based on combining funnels and elimination trees. Unfortunately, the funnels are linearizable but blocking, and the elimination trees are non-blocking but not linearizable. Neither is used in practice since they perform well only at exceptionally high loads. The literature also describes a simple lock-free linearizable stack algorithm that works at low loads but does not scale as the load increases. The question of designing a stack algorithm that is non-blocking, linearizable, and scales well throughout the concurrency range, has thus remained open.This paper presents such a concurrent stack algorithm. It is based on the following simple observation: that a single elimination array used as a backoff scheme for a simple lock-free stack is lock-free, linearizable, and scalable. As our empirical results show, the resulting elimination-backoff stack performs as well as the simple stack at low loads, and increasingly outperforms all other methods (lock-based and non-blocking) as concurrency increases. We believe its simplicity and scalability make it a viable practical alternative to existing constructions for implementing concurrent stacks.},
	booktitle = {Proceedings of the {Sixteenth} {Annual} {ACM} {Symposium} on {Parallelism} in {Algorithms} and {Architectures} ({SPAA})},
	author = {Hendler, Danny and Shavit, Nir and Yerushalmi, Lena},
	year = {2004},
	pages = {206--215},
	file = {p206-hendler.pdf:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\T3SD3AUH\\p206-hendler.pdf:application/pdf}
}

@misc{calciu_adaptive_2014-1,
	title = {The {Adaptive} {Priority} {Queue} with {Elimination} and {Combining}},
	url = {http://arxiv.org/abs/1408.1021},
	urldate = {2017-02-07},
	journal = {arXiv.org},
	author = {Calciu, Irina and Mendes, Hammurabi and Herlihy, Maurice},
	month = aug,
	year = {2014},
	keywords = {Computer Science - Distributed, Parallel, and Cluster Computing},
	file = {arXiv\:1408.1021 PDF:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\XIQX4AC3\\Calciu et al. - 2014 - The Adaptive Priority Queue with Elimination and C.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\5G2EH3GU\\1408.html:text/html}
}

@inproceedings{liu_mounds:_2012,
	title = {Mounds: {Array}-{Based} {Concurrent} {Priority} {Queues}},
	doi = {10.1145/2145816.2145876},
	abstract = {This paper introduces a concurrent data structure called the mound. The mound is a rooted tree of sorted lists that relies on randomization for balance. It supports O(log(log(N))) insert and O(log(N)) extract Min operations, making it suitable for use as a priority queue. We present two mound algorithms: the first achieves lock freedom via the use of a pure-software double-compare-and-swap (DCAS), and the second uses fine grained locks. Mounds perform well in practice, and support novel operations that we expect to be useful in parallel applications, such as extract Many and probabilistic extract Min.},
	booktitle = {Proceedings of the 17th {ACM} {SIGPLAN} {Symposium} on {Principles} and {Practice} of {Parallel} {Programming} ({PPoPP})},
	author = {Liu, Y. and Spear, M.},
	year = {2012},
	keywords = {abstract data types, array-based concurrent priority queues, Arrays, Complexity theory, computational complexity, concurrency control, concurrent data structure, DCAS, fine grained locks, Heap, Indexes, Linearizability, Lock-Freedom, lock freedom, mound algorithms, O(log(log(N))) insert Min operation, O(log(N)) extract Min operations, parallel applications, parallel processing, Priority Queue, pure-software double-compare-and-swap, Radiation detectors, randomization, rooted tree, Scalability, synchronization},
	pages = {323--324},
	file = {2386f95f11d0cd0844f6adca32a914eb19ae.pdf:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\NER9HB6V\\2386f95f11d0cd0844f6adca32a914eb19ae.pdf:application/pdf;IEEE Xplore Abstract Record:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\R2MTNFR8\\6337625.html:text/html}
}

@inproceedings{linden_skiplist-based_2013,
	title = {A {Skiplist}-{Based} {Concurrent} {Priority} {Queue} with {Minimal} {Memory} {Contention}},
	copyright = {©2013 Springer International Publishing Switzerland},
	doi = {10.1007/978-3-319-03850-6_15},
	abstract = {Priority queues are fundamental to many multiprocessor applications. Several priority queue algorithms based on skiplists have been proposed, as skiplists allow concurrent accesses to different parts of the data structure in a simple way. However, for priority queues on multiprocessors, an inherent bottleneck is the operation that deletes the minimal element. We present a linearizable, lock-free, concurrent priority queue algorithm, based on skiplists, which minimizes the contention for shared memory that is caused by the DeleteMin operation. The main idea is to minimize the number of global updates to shared memory that are performed in one DeleteMin. In comparison with other skiplist-based priority queue algorithms, our algorithm achieves a 30 - 80\% improvement.},
	booktitle = {Proceedings of the 17th {International} {Conference} {International} {Conference} {On} {Principles} {Of} {Distributed} {Systems} ({OPODIS})},
	author = {Lindén, Jonatan and Jonsson, Bengt},
	year = {2013},
	keywords = {Algorithm Analysis and Problem Complexity, Artificial Intelligence (incl. Robotics), Computation by Abstract Devices, Computer Communication Networks, Concurrent data structures, Discrete Mathematics in Computer Science, Lock-Free, Non-Blocking, Priority Queue, Skiplist, Software Engineering},
	pages = {206--220},
	file = {2013-025-nc.pdf:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\UMVWMZFV\\2013-025-nc.pdf:application/pdf;Snapshot:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\B4F6XPCD\\978-3-319-03850-6_15.html:text/html}
}

@techreport{pugh_concurrent_1990,
	title = {Concurrent {Maintenance} of {Skip} {Lists}},
	url = {http://drum.lib.umd.edu/handle/1903/542},
	institution = {University of Maryland at College Park},
	author = {Pugh, William},
	year = {1990},
	file = {10.1.1.17.8201.pdf:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\97555UD8\\10.1.1.17.8201.pdf:application/pdf}
}

@article{shavit_elimination_1997,
	title = {Elimination {Trees} and the {Construction} of {Pools} and {Stacks}},
	volume = {30},
	doi = {10.1007/s002240000072},
	abstract = {Shared pools and stacks are two coordination structures with a history of applications ranging from simple producer/consumer buffers to job-schedulers and procedure stacks. This paper introduces elimination trees, a novel form of diffracting trees that offer pool and stack implementations with superior response (on average constant) under high loads, while guaranteeing logarithmic time ``deterministic'' termination under sparse request patterns.},
	number = {6},
	journal = {Theory of Computing Systems},
	author = {Shavit, N. and Touitou, D.},
	year = {1997},
	pages = {645--670},
	file = {Snapshot:C\:\\Users\\stefa\\AppData\\Roaming\\Zotero\\Zotero\\Profiles\\eya1ases.default\\zotero\\storage\\495XV5U3\\s002240000072.html:text/html}
}